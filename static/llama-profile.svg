<?xml version="1.0" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" width="1200" height="838" onload="init(evt)" viewBox="0 0 1200 838" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<!-- Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples. -->
<!-- NOTES:  -->
<defs>
	<linearGradient id="background" y1="0" y2="1" x1="0" x2="0" >
		<stop stop-color="#eeeeee" offset="5%" />
		<stop stop-color="#eeeeb0" offset="95%" />
	</linearGradient>
</defs>
<style type="text/css">
	text { font-family:Verdana; font-size:12px; fill:rgb(0,0,0); }
	#search, #ignorecase { opacity:0.1; cursor:pointer; }
	#search:hover, #search.show, #ignorecase:hover, #ignorecase.show { opacity:1; }
	#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
	#title { text-anchor:middle; font-size:17px}
	#unzoom { cursor:pointer; }
	#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
	.hide { display:none; }
	.parent { opacity:0.5; }
</style>
<script type="text/ecmascript">
<![CDATA[
	"use strict";
	var details, searchbtn, unzoombtn, matchedtxt, svg, searching, currentSearchTerm, ignorecase, ignorecaseBtn;
	function init(evt) {
		details = document.getElementById("details").firstChild;
		searchbtn = document.getElementById("search");
		ignorecaseBtn = document.getElementById("ignorecase");
		unzoombtn = document.getElementById("unzoom");
		matchedtxt = document.getElementById("matched");
		svg = document.getElementsByTagName("svg")[0];
		searching = 0;
		currentSearchTerm = null;

		// use GET parameters to restore a flamegraphs state.
		var params = get_params();
		if (params.x && params.y)
			zoom(find_group(document.querySelector('[x="' + params.x + '"][y="' + params.y + '"]')));
                if (params.s) search(params.s);
	}

	// event listeners
	window.addEventListener("click", function(e) {
		var target = find_group(e.target);
		if (target) {
			if (target.nodeName == "a") {
				if (e.ctrlKey === false) return;
				e.preventDefault();
			}
			if (target.classList.contains("parent")) unzoom(true);
			zoom(target);
			if (!document.querySelector('.parent')) {
				// we have basically done a clearzoom so clear the url
				var params = get_params();
				if (params.x) delete params.x;
				if (params.y) delete params.y;
				history.replaceState(null, null, parse_params(params));
				unzoombtn.classList.add("hide");
				return;
			}

			// set parameters for zoom state
			var el = target.querySelector("rect");
			if (el && el.attributes && el.attributes.y && el.attributes._orig_x) {
				var params = get_params()
				params.x = el.attributes._orig_x.value;
				params.y = el.attributes.y.value;
				history.replaceState(null, null, parse_params(params));
			}
		}
		else if (e.target.id == "unzoom") clearzoom();
		else if (e.target.id == "search") search_prompt();
		else if (e.target.id == "ignorecase") toggle_ignorecase();
	}, false)

	// mouse-over for info
	// show
	window.addEventListener("mouseover", function(e) {
		var target = find_group(e.target);
		if (target) details.nodeValue = "Function: " + g_to_text(target);
	}, false)

	// clear
	window.addEventListener("mouseout", function(e) {
		var target = find_group(e.target);
		if (target) details.nodeValue = ' ';
	}, false)

	// ctrl-F for search
	// ctrl-I to toggle case-sensitive search
	window.addEventListener("keydown",function (e) {
		if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
			e.preventDefault();
			search_prompt();
		}
		else if (e.ctrlKey && e.keyCode === 73) {
			e.preventDefault();
			toggle_ignorecase();
		}
	}, false)

	// functions
	function get_params() {
		var params = {};
		var paramsarr = window.location.search.substr(1).split('&');
		for (var i = 0; i < paramsarr.length; ++i) {
			var tmp = paramsarr[i].split("=");
			if (!tmp[0] || !tmp[1]) continue;
			params[tmp[0]]  = decodeURIComponent(tmp[1]);
		}
		return params;
	}
	function parse_params(params) {
		var uri = "?";
		for (var key in params) {
			uri += key + '=' + encodeURIComponent(params[key]) + '&';
		}
		if (uri.slice(-1) == "&")
			uri = uri.substring(0, uri.length - 1);
		if (uri == '?')
			uri = window.location.href.split('?')[0];
		return uri;
	}
	function find_child(node, selector) {
		var children = node.querySelectorAll(selector);
		if (children.length) return children[0];
	}
	function find_group(node) {
		var parent = node.parentElement;
		if (!parent) return;
		if (parent.id == "frames") return node;
		return find_group(parent);
	}
	function orig_save(e, attr, val) {
		if (e.attributes["_orig_" + attr] != undefined) return;
		if (e.attributes[attr] == undefined) return;
		if (val == undefined) val = e.attributes[attr].value;
		e.setAttribute("_orig_" + attr, val);
	}
	function orig_load(e, attr) {
		if (e.attributes["_orig_"+attr] == undefined) return;
		e.attributes[attr].value = e.attributes["_orig_" + attr].value;
		e.removeAttribute("_orig_"+attr);
	}
	function g_to_text(e) {
		var text = find_child(e, "title").firstChild.nodeValue;
		return (text)
	}
	function g_to_func(e) {
		var func = g_to_text(e);
		// if there's any manipulation we want to do to the function
		// name before it's searched, do it here before returning.
		return (func);
	}
	function update_text(e) {
		var r = find_child(e, "rect");
		var t = find_child(e, "text");
		var w = parseFloat(r.attributes.width.value) -3;
		var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
		t.attributes.x.value = parseFloat(r.attributes.x.value) + 3;

		// Smaller than this size won't fit anything
		if (w < 2 * 12 * 0.59) {
			t.textContent = "";
			return;
		}

		t.textContent = txt;
		var sl = t.getSubStringLength(0, txt.length);
		// check if only whitespace or if we can fit the entire string into width w
		if (/^ *$/.test(txt) || sl < w)
			return;

		// this isn't perfect, but gives a good starting point
		// and avoids calling getSubStringLength too often
		var start = Math.floor((w/sl) * txt.length);
		for (var x = start; x > 0; x = x-2) {
			if (t.getSubStringLength(0, x + 2) <= w) {
				t.textContent = txt.substring(0, x) + "..";
				return;
			}
		}
		t.textContent = "";
	}

	// zoom
	function zoom_reset(e) {
		if (e.attributes != undefined) {
			orig_load(e, "x");
			orig_load(e, "width");
		}
		if (e.childNodes == undefined) return;
		for (var i = 0, c = e.childNodes; i < c.length; i++) {
			zoom_reset(c[i]);
		}
	}
	function zoom_child(e, x, ratio) {
		if (e.attributes != undefined) {
			if (e.attributes.x != undefined) {
				orig_save(e, "x");
				e.attributes.x.value = (parseFloat(e.attributes.x.value) - x - 10) * ratio + 10;
				if (e.tagName == "text")
					e.attributes.x.value = find_child(e.parentNode, "rect[x]").attributes.x.value + 3;
			}
			if (e.attributes.width != undefined) {
				orig_save(e, "width");
				e.attributes.width.value = parseFloat(e.attributes.width.value) * ratio;
			}
		}

		if (e.childNodes == undefined) return;
		for (var i = 0, c = e.childNodes; i < c.length; i++) {
			zoom_child(c[i], x - 10, ratio);
		}
	}
	function zoom_parent(e) {
		if (e.attributes) {
			if (e.attributes.x != undefined) {
				orig_save(e, "x");
				e.attributes.x.value = 10;
			}
			if (e.attributes.width != undefined) {
				orig_save(e, "width");
				e.attributes.width.value = parseInt(svg.width.baseVal.value) - (10 * 2);
			}
		}
		if (e.childNodes == undefined) return;
		for (var i = 0, c = e.childNodes; i < c.length; i++) {
			zoom_parent(c[i]);
		}
	}
	function zoom(node) {
		var attr = find_child(node, "rect").attributes;
		var width = parseFloat(attr.width.value);
		var xmin = parseFloat(attr.x.value);
		var xmax = parseFloat(xmin + width);
		var ymin = parseFloat(attr.y.value);
		var ratio = (svg.width.baseVal.value - 2 * 10) / width;

		// XXX: Workaround for JavaScript float issues (fix me)
		var fudge = 0.0001;

		unzoombtn.classList.remove("hide");

		var el = document.getElementById("frames").children;
		for (var i = 0; i < el.length; i++) {
			var e = el[i];
			var a = find_child(e, "rect").attributes;
			var ex = parseFloat(a.x.value);
			var ew = parseFloat(a.width.value);
			var upstack;
			// Is it an ancestor
			if (0 == 0) {
				upstack = parseFloat(a.y.value) > ymin;
			} else {
				upstack = parseFloat(a.y.value) < ymin;
			}
			if (upstack) {
				// Direct ancestor
				if (ex <= xmin && (ex+ew+fudge) >= xmax) {
					e.classList.add("parent");
					zoom_parent(e);
					update_text(e);
				}
				// not in current path
				else
					e.classList.add("hide");
			}
			// Children maybe
			else {
				// no common path
				if (ex < xmin || ex + fudge >= xmax) {
					e.classList.add("hide");
				}
				else {
					zoom_child(e, xmin, ratio);
					update_text(e);
				}
			}
		}
		search();
	}
	function unzoom(dont_update_text) {
		unzoombtn.classList.add("hide");
		var el = document.getElementById("frames").children;
		for(var i = 0; i < el.length; i++) {
			el[i].classList.remove("parent");
			el[i].classList.remove("hide");
			zoom_reset(el[i]);
			if(!dont_update_text) update_text(el[i]);
		}
		search();
	}
	function clearzoom() {
		unzoom();

		// remove zoom state
		var params = get_params();
		if (params.x) delete params.x;
		if (params.y) delete params.y;
		history.replaceState(null, null, parse_params(params));
	}

	// search
	function toggle_ignorecase() {
		ignorecase = !ignorecase;
		if (ignorecase) {
			ignorecaseBtn.classList.add("show");
		} else {
			ignorecaseBtn.classList.remove("show");
		}
		reset_search();
		search();
	}
	function reset_search() {
		var el = document.querySelectorAll("#frames rect");
		for (var i = 0; i < el.length; i++) {
			orig_load(el[i], "fill")
		}
		var params = get_params();
		delete params.s;
		history.replaceState(null, null, parse_params(params));
	}
	function search_prompt() {
		if (!searching) {
			var term = prompt("Enter a search term (regexp " +
			    "allowed, eg: ^ext4_)"
			    + (ignorecase ? ", ignoring case" : "")
			    + "\nPress Ctrl-i to toggle case sensitivity", "");
			if (term != null) search(term);
		} else {
			reset_search();
			searching = 0;
			currentSearchTerm = null;
			searchbtn.classList.remove("show");
			searchbtn.firstChild.nodeValue = "Search"
			matchedtxt.classList.add("hide");
			matchedtxt.firstChild.nodeValue = ""
		}
	}
	function search(term) {
		if (term) currentSearchTerm = term;

		var re = new RegExp(currentSearchTerm, ignorecase ? 'i' : '');
		var el = document.getElementById("frames").children;
		var matches = new Object();
		var maxwidth = 0;
		for (var i = 0; i < el.length; i++) {
			var e = el[i];
			var func = g_to_func(e);
			var rect = find_child(e, "rect");
			if (func == null || rect == null)
				continue;

			// Save max width. Only works as we have a root frame
			var w = parseFloat(rect.attributes.width.value);
			if (w > maxwidth)
				maxwidth = w;

			if (func.match(re)) {
				// highlight
				var x = parseFloat(rect.attributes.x.value);
				orig_save(rect, "fill");
				rect.attributes.fill.value = "rgb(230,0,230)";

				// remember matches
				if (matches[x] == undefined) {
					matches[x] = w;
				} else {
					if (w > matches[x]) {
						// overwrite with parent
						matches[x] = w;
					}
				}
				searching = 1;
			}
		}
		if (!searching)
			return;
		var params = get_params();
		params.s = currentSearchTerm;
		history.replaceState(null, null, parse_params(params));

		searchbtn.classList.add("show");
		searchbtn.firstChild.nodeValue = "Reset Search";

		// calculate percent matched, excluding vertical overlap
		var count = 0;
		var lastx = -1;
		var lastw = 0;
		var keys = Array();
		for (k in matches) {
			if (matches.hasOwnProperty(k))
				keys.push(k);
		}
		// sort the matched frames by their x location
		// ascending, then width descending
		keys.sort(function(a, b){
			return a - b;
		});
		// Step through frames saving only the biggest bottom-up frames
		// thanks to the sort order. This relies on the tree property
		// where children are always smaller than their parents.
		var fudge = 0.0001;	// JavaScript floating point
		for (var k in keys) {
			var x = parseFloat(keys[k]);
			var w = matches[keys[k]];
			if (x >= lastx + lastw - fudge) {
				count += w;
				lastx = x;
				lastw = w;
			}
		}
		// display matched percent
		matchedtxt.classList.remove("hide");
		var pct = 100 * count / maxwidth;
		if (pct != 100) pct = pct.toFixed(1)
		matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
	}
]]>
</script>
<rect x="0.0" y="0" width="1200.0" height="838.0" fill="url(#background)"  />
<text id="title" x="600.00" y="24" >CUDA time</text>
<text id="details" x="10.00" y="821" > </text>
<text id="unzoom" x="10.00" y="24" class="hide">Reset Zoom</text>
<text id="search" x="1090.00" y="24" >Search</text>
<text id="ignorecase" x="1174.00" y="24" >ic</text>
<text id="matched" x="1090.00" y="821" > </text>
<g id="frames">
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,254 us., 0.68%)</title><rect x="236.7" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="239.69" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (176 us., 0.03%)</title><rect x="453.9" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="456.93" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (213 us., 0.03%)</title><rect x="173.6" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="176.56" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,250 us., 0.20%)</title><rect x="697.1" y="69" width="2.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="700.06" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (265 us., 0.04%)</title><rect x="1179.5" y="117" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1182.49" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,334 us., 0.37%)</title><rect x="745.2" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="748.18" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,342 us., 0.38%)</title><rect x="979.3" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="982.31" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (65 us., 0.01%)</title><rect x="207.2" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="210.15" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (30,330 us., 4.87%)</title><rect x="786.0" y="133" width="57.4" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="788.96" y="143.5" >transf..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (26,416 us., 4.24%)</title><rect x="364.5" y="133" width="50.1" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="367.52" y="143.5" >trans..</text>
</g>
<g >
<title>nn.Module:_Linear_154 (16,162 us., 2.59%)</title><rect x="16.1" y="181" width="30.6" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="19.10" y="191.5" >nn..</text>
</g>
<g >
<title>nn.Module:_Linear_62 (6,026 us., 0.97%)</title><rect x="1110.7" y="85" width="11.4" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="1113.67" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,256 us., 0.68%)</title><rect x="940.9" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="943.89" y="63.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (80 us., 0.01%)</title><rect x="686.3" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="689.28" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (2,899 us., 0.47%)</title><rect x="868.7" y="85" width="5.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="871.68" y="95.5" ></text>
</g>
<g >
<title>torch/autograd/grad_mode.py(24):_decorate_context (623,010 us., 100.00%)</title><rect x="10.0" y="261" width="1180.0" height="15.0" fill="rgb(211,29,7)" rx="2" ry="2" />
<text  x="13.00" y="271.5" >torch/autograd/grad_mode.py(24):_decorate_context</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,853 us., 0.78%)</title><rect x="572.8" y="69" width="9.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="575.82" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (254 us., 0.04%)</title><rect x="227.5" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="230.52" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (11,087 us., 1.78%)</title><rect x="786.3" y="101" width="21.0" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="789.29" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_40 (4,256 us., 0.68%)</title><rect x="940.9" y="85" width="8.1" height="15.0" fill="rgb(235,140,33)" rx="2" ry="2" />
<text  x="943.89" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,345 us., 0.38%)</title><rect x="61.4" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="64.40" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,260 us., 0.68%)</title><rect x="1155.1" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1158.15" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,447 us., 0.55%)</title><rect x="516.3" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="519.25" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (120 us., 0.02%)</title><rect x="690.9" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="693.91" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,869 us., 0.30%)</title><rect x="424.5" y="53" width="3.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="427.51" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,330 us., 0.37%)</title><rect x="318.0" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="320.99" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,311 us., 0.69%)</title><rect x="385.5" y="53" width="8.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="388.51" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,273 us., 0.20%)</title><rect x="461.8" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="464.79" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (803 us., 0.13%)</title><rect x="496.0" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="499.01" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_26 (1,059 us., 0.17%)</title><rect x="308.8" y="117" width="2.0" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="311.78" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_0 (16,063 us., 2.58%)</title><rect x="70.7" y="117" width="30.4" height="15.0" fill="rgb(215,48,11)" rx="2" ry="2" />
<text  x="73.67" y="127.5" >nn..</text>
</g>
<g >
<title>nn.Module:_Linear_27 (6,031 us., 0.97%)</title><rect x="823.9" y="85" width="11.4" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="826.87" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_11 (85 us., 0.01%)</title><rect x="204.5" y="85" width="0.2" height="15.0" fill="rgb(208,13,3)" rx="2" ry="2" />
<text  x="207.51" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,332 us., 0.37%)</title><rect x="169.1" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="172.15" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(986):_forward (615,122 us., 98.73%)</title><rect x="15.8" y="197" width="1165.1" height="15.0" fill="rgb(254,229,54)" rx="2" ry="2" />
<text  x="18.81" y="207.5" >transformers/models/llama/modeling_llama.py(986):_forward</text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (315 us., 0.05%)</title><rect x="932.0" y="69" width="0.6" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="935.04" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,985 us., 0.80%)</title><rect x="401.8" y="53" width="9.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="404.78" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_9 (847 us., 0.14%)</title><rect x="904.2" y="117" width="1.6" height="15.0" fill="rgb(237,151,36)" rx="2" ry="2" />
<text  x="907.20" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,711 us., 0.27%)</title><rect x="373.9" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="376.91" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_153 (4,763 us., 0.76%)</title><rect x="719.7" y="85" width="9.0" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="722.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,728 us., 0.28%)</title><rect x="370.6" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="373.64" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_1 (847 us., 0.14%)</title><rect x="102.9" y="117" width="1.6" height="15.0" fill="rgb(239,158,37)" rx="2" ry="2" />
<text  x="105.89" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (160 us., 0.03%)</title><rect x="785.0" y="85" width="0.3" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="788.02" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,985 us., 0.80%)</title><rect x="401.8" y="69" width="9.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="404.78" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,280 us., 0.69%)</title><rect x="70.8" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="73.84" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_94 (2,342 us., 0.38%)</title><rect x="272.5" y="85" width="4.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="275.49" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_101 (2,330 us., 0.37%)</title><rect x="318.0" y="85" width="4.4" height="15.0" fill="rgb(238,153,36)" rx="2" ry="2" />
<text  x="320.99" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,437 us., 0.55%)</title><rect x="664.3" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="667.29" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_137 (3,449 us., 0.55%)</title><rect x="559.8" y="85" width="6.5" height="15.0" fill="rgb(230,115,27)" rx="2" ry="2" />
<text  x="562.78" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,858 us., 0.30%)</title><rect x="699.4" y="69" width="3.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="702.43" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_92 (1,722 us., 0.28%)</title><rect x="266.0" y="85" width="3.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="268.97" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="362.3" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="365.34" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (70 us., 0.01%)</title><rect x="1016.0" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1018.99" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="454.4" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="457.39" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (280 us., 0.04%)</title><rect x="643.2" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="646.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (69 us., 0.01%)</title><rect x="1072.9" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1075.91" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_68 (4,260 us., 0.68%)</title><rect x="1155.1" y="85" width="8.1" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="1158.15" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_16 (8,578 us., 1.38%)</title><rect x="414.9" y="117" width="16.2" height="15.0" fill="rgb(228,108,25)" rx="2" ry="2" />
<text  x="417.87" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (266 us., 0.04%)</title><rect x="539.9" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="542.87" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_57 (1,782 us., 0.29%)</title><rect x="1079.9" y="85" width="3.4" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="1082.89" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,253 us., 0.20%)</title><rect x="654.7" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="657.71" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_32 (804 us., 0.13%)</title><rect x="453.5" y="117" width="1.5" height="15.0" fill="rgb(253,223,53)" rx="2" ry="2" />
<text  x="456.50" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_122 (1,873 us., 0.30%)</title><rect x="466.6" y="85" width="3.5" height="15.0" fill="rgb(218,64,15)" rx="2" ry="2" />
<text  x="469.60" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (206 us., 0.03%)</title><rect x="121.6" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="124.56" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_17 (22,665 us., 3.64%)</title><rect x="456.5" y="149" width="43.0" height="15.0" fill="rgb(237,150,36)" rx="2" ry="2" />
<text  x="459.55" y="159.5" >nn.M..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (860 us., 0.14%)</title><rect x="782.5" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="785.51" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_2 (11,605 us., 1.86%)</title><rect x="732.6" y="117" width="22.0" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="735.63" y="127.5" >n..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,756 us., 0.76%)</title><rect x="529.3" y="69" width="9.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="532.31" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,028 us., 0.97%)</title><rect x="1003.4" y="53" width="11.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1006.44" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (225 us., 0.04%)</title><rect x="384.9" y="69" width="0.5" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="387.93" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_multinomial_of_type_object_at_0x7b66dec9e9c0&gt; (2,050 us., 0.33%)</title><rect x="11.3" y="213" width="3.9" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="14.32" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (351 us., 0.06%)</title><rect x="705.4" y="53" width="0.7" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="708.44" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,873 us., 0.30%)</title><rect x="466.6" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="469.60" y="79.5" ></text>
</g>
<g >
<title>tornado/gen.py(825):_inner (623,012 us., 100.00%)</title><rect x="10.0" y="597" width="1180.0" height="15.0" fill="rgb(249,202,48)" rx="2" ry="2" />
<text  x="13.00" y="607.5" >tornado/gen.py(825):_inner</text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (318 us., 0.05%)</title><rect x="280.0" y="69" width="0.6" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="282.97" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (847 us., 0.14%)</title><rect x="904.2" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="907.20" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,345 us., 0.38%)</title><rect x="61.4" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="64.40" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (62 us., 0.01%)</title><rect x="258.9" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="261.90" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (927 us., 0.15%)</title><rect x="1015.0" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1018.03" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,744 us., 0.28%)</title><rect x="1132.2" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1135.20" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_74 (4,268 us., 0.69%)</title><rect x="125.1" y="85" width="8.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="128.07" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_89 (4,254 us., 0.68%)</title><rect x="236.7" y="85" width="8.0" height="15.0" fill="rgb(251,213,51)" rx="2" ry="2" />
<text  x="239.69" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (74 us., 0.01%)</title><rect x="905.1" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="908.12" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_23 (816 us., 0.13%)</title><rect x="206.3" y="117" width="1.5" height="15.0" fill="rgb(253,223,53)" rx="2" ry="2" />
<text  x="209.25" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (68 us., 0.01%)</title><rect x="582.9" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="585.92" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,728 us., 0.28%)</title><rect x="738.6" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="741.64" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,253 us., 0.20%)</title><rect x="654.7" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="657.71" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_127 (1,285 us., 0.21%)</title><rect x="504.7" y="85" width="2.4" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="507.66" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,206 us., 0.19%)</title><rect x="513.4" y="85" width="2.3" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="516.39" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (198 us., 0.03%)</title><rect x="225.0" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="228.04" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_133 (1,860 us., 0.30%)</title><rect x="544.0" y="85" width="3.5" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="547.02" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (74 us., 0.01%)</title><rect x="312.1" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="315.08" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_13 (28,128 us., 4.51%)</title><rect x="259.7" y="149" width="53.2" height="15.0" fill="rgb(213,39,9)" rx="2" ry="2" />
<text  x="262.66" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>asyncio/base_events.py(603):_run_forever (623,012 us., 100.00%)</title><rect x="10.0" y="677" width="1180.0" height="15.0" fill="rgb(239,160,38)" rx="2" ry="2" />
<text  x="13.00" y="687.5" >asyncio/base_events.py(603):_run_forever</text>
</g>
<g >
<title>nn.Module:_Linear_2 (1,731 us., 0.28%)</title><rect x="58.1" y="85" width="3.3" height="15.0" fill="rgb(208,16,3)" rx="2" ry="2" />
<text  x="61.12" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (288 us., 0.05%)</title><rect x="1125.3" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1128.26" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_0 (12,348 us., 1.98%)</title><rect x="47.3" y="117" width="23.4" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="50.28" y="127.5" >n..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (453 us., 0.07%)</title><rect x="332.0" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="335.03" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,737 us., 0.28%)</title><rect x="852.6" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="855.56" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,252 us., 0.68%)</title><rect x="754.8" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="757.77" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,329 us., 0.37%)</title><rect x="1075.5" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1078.48" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,917 us., 0.31%)</title><rect x="795.7" y="69" width="3.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="798.68" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_14 (10,550 us., 1.69%)</title><rect x="313.3" y="117" width="20.0" height="15.0" fill="rgb(241,167,40)" rx="2" ry="2" />
<text  x="316.34" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (106 us., 0.02%)</title><rect x="10.7" y="213" width="0.2" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="13.70" y="223.5" ></text>
</g>
<g >
<title>torch/nn/modules/sparse.py(159):_forward (125 us., 0.02%)</title><rect x="46.7" y="133" width="0.2" height="15.0" fill="rgb(245,185,44)" rx="2" ry="2" />
<text  x="49.71" y="143.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,352 us., 0.70%)</title><rect x="333.5" y="69" width="8.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="336.50" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_16 (1,726 us., 0.28%)</title><rect x="741.9" y="85" width="3.3" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="744.91" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,111 us., 0.98%)</title><rect x="89.4" y="69" width="11.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="92.37" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (206 us., 0.03%)</title><rect x="276.9" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="279.93" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,445 us., 0.55%)</title><rect x="480.3" y="69" width="6.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="483.33" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,197 us., 0.19%)</title><rect x="428.4" y="85" width="2.3" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="431.44" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (162 us., 0.03%)</title><rect x="686.9" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="689.89" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (226 us., 0.04%)</title><rect x="515.7" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="518.67" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,170 us., 3.56%)</title><rect x="414.6" y="133" width="41.9" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="417.56" y="143.5" >tra..</text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (80 us., 0.01%)</title><rect x="453.3" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="456.35" y="47.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="256.1" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="259.15" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (206 us., 0.03%)</title><rect x="121.6" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="124.56" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_23 (1,917 us., 0.31%)</title><rect x="795.7" y="85" width="3.6" height="15.0" fill="rgb(229,110,26)" rx="2" ry="2" />
<text  x="798.68" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (221 us., 0.04%)</title><rect x="983.8" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="986.75" y="79.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (91 us., 0.01%)</title><rect x="835.3" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="838.29" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,255 us., 0.68%)</title><rect x="995.4" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="998.38" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_130 (3,447 us., 0.55%)</title><rect x="516.3" y="85" width="6.5" height="15.0" fill="rgb(225,93,22)" rx="2" ry="2" />
<text  x="519.25" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,447 us., 0.55%)</title><rect x="516.3" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="519.25" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (202 us., 0.03%)</title><rect x="868.3" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="871.30" y="79.5" ></text>
</g>
<g >
<title>tornado/gen.py(786):_run (623,012 us., 100.00%)</title><rect x="10.0" y="517" width="1180.0" height="15.0" fill="rgb(245,187,44)" rx="2" ry="2" />
<text  x="13.00" y="527.5" >tornado/gen.py(786):_run</text>
</g>
<g >
<title>nn.Module:_Linear_152 (3,447 us., 0.55%)</title><rect x="713.2" y="85" width="6.5" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="716.18" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_8 (14,712 us., 2.36%)</title><rect x="1094.4" y="117" width="27.8" height="15.0" fill="rgb(213,41,9)" rx="2" ry="2" />
<text  x="1097.37" y="127.5" >n..</text>
</g>
<g >
<title>nn.Module:_Linear_112 (1,859 us., 0.30%)</title><rect x="416.2" y="85" width="3.5" height="15.0" fill="rgb(225,93,22)" rx="2" ry="2" />
<text  x="419.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (230 us., 0.04%)</title><rect x="847.5" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="850.48" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (72 us., 0.01%)</title><rect x="903.5" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="906.53" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,802 us., 1.89%)</title><rect x="706.5" y="101" width="22.4" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="709.53" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="100.9" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="103.94" y="47.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_17 (11,813 us., 1.90%)</title><rect x="473.6" y="117" width="22.4" height="15.0" fill="rgb(253,224,53)" rx="2" ry="2" />
<text  x="476.64" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,299 us., 0.69%)</title><rect x="807.5" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="810.46" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,249 us., 0.52%)</title><rect x="913.7" y="53" width="6.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="916.73" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaForCausalLM_0 (615,122 us., 98.73%)</title><rect x="15.8" y="213" width="1165.1" height="15.0" fill="rgb(244,180,43)" rx="2" ry="2" />
<text  x="18.81" y="223.5" >nn.Module:_LlamaForCausalLM_0</text>
</g>
<g >
<title>nn.Module:_SiLUActivation_15 (85 us., 0.01%)</title><rect x="411.2" y="85" width="0.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="414.22" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,716 us., 2.36%)</title><rect x="1146.9" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="1149.93" y="111.5" >t..</text>
</g>
<g >
<title>&lt;ipython-input-4-98c943707796&gt;(1):_&lt;cell_line:_1&gt; (623,012 us., 100.00%)</title><rect x="10.0" y="277" width="1180.0" height="15.0" fill="rgb(210,24,5)" rx="2" ry="2" />
<text  x="13.00" y="287.5" >&lt;ipython-input-4-98c943707796&gt;(1):_&lt;cell_line:_1&gt;</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_21 (832 us., 0.13%)</title><rect x="154.3" y="117" width="1.6" height="15.0" fill="rgb(216,53,12)" rx="2" ry="2" />
<text  x="157.35" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,262 us., 0.20%)</title><rect x="550.0" y="53" width="2.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="552.96" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,322 us., 0.37%)</title><rect x="734.2" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="737.24" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_17 (943 us., 0.15%)</title><rect x="1124.0" y="117" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1127.02" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_21 (22,637 us., 3.63%)</title><rect x="689.4" y="149" width="42.9" height="15.0" fill="rgb(220,69,16)" rx="2" ry="2" />
<text  x="692.43" y="159.5" >nn.M..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (215 us., 0.03%)</title><rect x="176.4" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="179.37" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (364 us., 0.06%)</title><rect x="1145.6" y="53" width="0.7" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1148.63" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_61 (4,244 us., 0.68%)</title><rect x="1102.6" y="85" width="8.1" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="1105.63" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_21 (8,860 us., 1.42%)</title><rect x="689.8" y="117" width="16.7" height="15.0" fill="rgb(254,227,54)" rx="2" ry="2" />
<text  x="692.75" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_43 (1,729 us., 0.28%)</title><rect x="971.8" y="85" width="3.2" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="974.77" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (216 us., 0.03%)</title><rect x="228.0" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="231.00" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (68 us., 0.01%)</title><rect x="153.7" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="156.71" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_10 (82 us., 0.01%)</title><rect x="152.7" y="85" width="0.1" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="155.65" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (220 us., 0.04%)</title><rect x="605.7" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="608.71" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_82 (4,258 us., 0.68%)</title><rect x="185.0" y="85" width="8.1" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="188.02" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,319 us., 0.37%)</title><rect x="366.2" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="369.25" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_140 (1,853 us., 0.30%)</title><rect x="648.8" y="85" width="3.5" height="15.0" fill="rgb(218,64,15)" rx="2" ry="2" />
<text  x="651.78" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (162 us., 0.03%)</title><rect x="496.5" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="499.46" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (92 us., 0.01%)</title><rect x="902.4" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="905.43" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (313 us., 0.05%)</title><rect x="1038.9" y="69" width="0.6" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="1041.91" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_29 (1,737 us., 0.28%)</title><rect x="852.6" y="85" width="3.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="855.56" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (193 us., 0.03%)</title><rect x="47.7" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="50.66" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,617 us., 0.58%)</title><rect x="861.4" y="69" width="6.9" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="864.45" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (228 us., 0.04%)</title><rect x="733.4" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="736.41" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_118 (4,758 us., 0.76%)</title><rect x="444.3" y="85" width="9.0" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="447.34" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,371 us., 0.38%)</title><rect x="591.7" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="594.73" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,859 us., 0.30%)</title><rect x="416.2" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="419.20" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (186 us., 0.03%)</title><rect x="690.1" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="693.09" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_4 (14,796 us., 2.37%)</title><rect x="874.6" y="117" width="28.0" height="15.0" fill="rgb(239,159,38)" rx="2" ry="2" />
<text  x="877.58" y="127.5" >n..</text>
</g>
<g >
<title>nn.Module:_Linear_64 (1,744 us., 0.28%)</title><rect x="1132.2" y="85" width="3.3" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="1135.20" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,570 us., 4.43%)</title><rect x="1073.6" y="133" width="52.2" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="1076.59" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,277 us., 0.69%)</title><rect x="393.7" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="396.67" y="63.5" ></text>
</g>
<g >
<title>asyncio/events.py(80):__run (623,012 us., 100.00%)</title><rect x="10.0" y="645" width="1180.0" height="15.0" fill="rgb(241,166,39)" rx="2" ry="2" />
<text  x="13.00" y="655.5" >asyncio/events.py(80):__run</text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (313 us., 0.05%)</title><rect x="1038.9" y="85" width="0.6" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1041.91" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (258 us., 0.04%)</title><rect x="663.2" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="666.22" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,339 us., 0.38%)</title><rect x="788.0" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="790.96" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,023 us., 0.97%)</title><rect x="949.0" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="951.95" y="63.5" ></text>
</g>
<g >
<title>ipykernel/zmqshell.py(539):_run_cell (623,012 us., 100.00%)</title><rect x="10.0" y="389" width="1180.0" height="15.0" fill="rgb(243,175,42)" rx="2" ry="2" />
<text  x="13.00" y="399.5" >ipykernel/zmqshell.py(539):_run_cell</text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (219 us., 0.04%)</title><rect x="986.7" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="989.69" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (799 us., 0.13%)</title><rect x="728.9" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="731.88" y="111.5" ></text>
</g>
<g >
<title>tornado/gen.py(234):_wrapper (623,012 us., 100.00%)</title><rect x="10.0" y="453" width="1180.0" height="15.0" fill="rgb(208,16,3)" rx="2" ry="2" />
<text  x="13.00" y="463.5" >tornado/gen.py(234):_wrapper</text>
</g>
<g >
<title>IPython/core/interactiveshell.py(3030):__run_cell (623,012 us., 100.00%)</title><rect x="10.0" y="357" width="1180.0" height="15.0" fill="rgb(233,130,31)" rx="2" ry="2" />
<text  x="13.00" y="367.5" >IPython/core/interactiveshell.py(3030):__run_cell</text>
</g>
<g >
<title>nn.Module:_LlamaAttention_17 (8,863 us., 1.42%)</title><rect x="456.8" y="117" width="16.8" height="15.0" fill="rgb(222,78,18)" rx="2" ry="2" />
<text  x="459.85" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,111 us., 0.98%)</title><rect x="89.4" y="53" width="11.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="92.37" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,493 us., 3.61%)</title><rect x="646.8" y="133" width="42.6" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="649.83" y="143.5" >tran..</text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (80 us., 0.01%)</title><rect x="686.3" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="689.28" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,006 us., 0.16%)</title><rect x="730.4" y="101" width="1.9" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="733.40" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_6 (11,177 us., 1.79%)</title><rect x="965.9" y="117" width="21.2" height="15.0" fill="rgb(245,184,44)" rx="2" ry="2" />
<text  x="968.93" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,438 us., 0.39%)</title><rect x="377.2" y="53" width="4.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="380.15" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_63 (2,330 us., 0.37%)</title><rect x="1127.8" y="85" width="4.4" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="1130.79" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_19 (9,113 us., 1.46%)</title><rect x="542.4" y="117" width="17.2" height="15.0" fill="rgb(209,19,4)" rx="2" ry="2" />
<text  x="545.35" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (65 us., 0.01%)</title><rect x="103.8" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="106.82" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (329 us., 0.05%)</title><rect x="586.4" y="85" width="0.7" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="589.45" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_12 (82 us., 0.01%)</title><rect x="256.1" y="85" width="0.2" height="15.0" fill="rgb(251,214,51)" rx="2" ry="2" />
<text  x="259.15" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (861 us., 0.14%)</title><rect x="1072.0" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1074.95" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (1,718 us., 0.28%)</title><rect x="1019.7" y="85" width="3.2" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="1022.65" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,731 us., 0.28%)</title><rect x="58.1" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="61.12" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,728 us., 0.28%)</title><rect x="217.4" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="220.36" y="79.5" ></text>
</g>
<g >
<title>transformers/generation/utils.py(768):__update_model_kwargs_for_generation (154 us., 0.02%)</title><rect x="1188.4" y="213" width="0.3" height="15.0" fill="rgb(207,9,2)" rx="2" ry="2" />
<text  x="1191.44" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (103 us., 0.02%)</title><rect x="308.6" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="311.59" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_float_of_Tensor_object_at_0x7b673c555760&gt; (154 us., 0.02%)</title><rect x="15.8" y="181" width="0.3" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="18.81" y="191.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (880 us., 0.14%)</title><rect x="540.4" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="543.37" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (264 us., 0.04%)</title><rect x="753.7" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="756.68" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (212 us., 0.03%)</title><rect x="1017.2" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1020.23" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,854 us., 0.30%)</title><rect x="691.1" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="694.13" y="63.5" ></text>
</g>
<g >
<title>transformers/modeling_attn_mask_utils.py(149):__expand_mask (399 us., 0.06%)</title><rect x="1180.1" y="117" width="0.8" height="15.0" fill="rgb(247,194,46)" rx="2" ry="2" />
<text  x="1183.11" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (218 us., 0.03%)</title><rect x="1094.0" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="1096.96" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,032 us., 0.97%)</title><rect x="193.1" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="196.09" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,712 us., 2.36%)</title><rect x="1094.4" y="101" width="27.8" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="1097.37" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (194 us., 0.03%)</title><rect x="542.7" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="545.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,368 us., 0.70%)</title><rect x="616.7" y="53" width="8.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="619.71" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (263 us., 0.04%)</title><rect x="1093.5" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1096.46" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_70 (2,323 us., 0.37%)</title><rect x="106.2" y="85" width="4.4" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="109.21" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,278 us., 0.69%)</title><rect x="1094.5" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1097.53" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,237 us., 4.37%)</title><rect x="312.9" y="133" width="51.6" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="315.94" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,263 us., 0.68%)</title><rect x="1050.7" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1053.71" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (294 us., 0.05%)</title><rect x="986.1" y="53" width="0.6" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="989.13" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,003 us., 0.32%)</title><rect x="552.3" y="53" width="3.8" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="555.35" y="63.5" ></text>
</g>
<g >
<title>tornado/gen.py(748):___init__ (623,012 us., 100.00%)</title><rect x="10.0" y="533" width="1180.0" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="13.00" y="543.5" >tornado/gen.py(748):___init__</text>
</g>
<g >
<title>transformers/generation/utils.py(2612):_sample (622,772 us., 99.96%)</title><rect x="10.1" y="229" width="1179.5" height="15.0" fill="rgb(246,190,45)" rx="2" ry="2" />
<text  x="13.10" y="239.5" >transformers/generation/utils.py(2612):_sample</text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (269 us., 0.04%)</title><rect x="102.4" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="105.38" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,166 us., 0.51%)</title><rect x="907.7" y="53" width="6.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="910.73" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_6 (14,745 us., 2.37%)</title><rect x="987.1" y="117" width="27.9" height="15.0" fill="rgb(226,100,24)" rx="2" ry="2" />
<text  x="990.10" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_prod_of_Tensor_object_at_0x7b6685852b10&gt; (171 us., 0.03%)</title><rect x="15.3" y="213" width="0.4" height="15.0" fill="rgb(229,113,27)" rx="2" ry="2" />
<text  x="18.34" y="223.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (467 us., 0.07%)</title><rect x="806.0" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="808.97" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,757 us., 1.73%)</title><rect x="1074.0" y="101" width="20.4" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="1077.00" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (63 us., 0.01%)</title><rect x="541.3" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="544.31" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,723 us., 0.28%)</title><rect x="1083.3" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1086.27" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_97 (6,027 us., 0.97%)</title><rect x="297.2" y="85" width="11.4" height="15.0" fill="rgb(207,13,3)" rx="2" ry="2" />
<text  x="300.17" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,726 us., 0.28%)</title><rect x="110.6" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="113.61" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_21 (2,339 us., 0.38%)</title><rect x="788.0" y="85" width="4.4" height="15.0" fill="rgb(241,169,40)" rx="2" ry="2" />
<text  x="790.96" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,400 us., 0.22%)</title><rect x="277.3" y="85" width="2.7" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="280.32" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,732 us., 0.28%)</title><rect x="326.8" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="329.80" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (171 us., 0.03%)</title><rect x="153.3" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="156.26" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (168 us., 0.03%)</title><rect x="584.1" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="587.12" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_25 (4,299 us., 0.69%)</title><rect x="807.5" y="85" width="8.1" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="810.46" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_120 (1,273 us., 0.20%)</title><rect x="461.8" y="85" width="2.4" height="15.0" fill="rgb(231,123,29)" rx="2" ry="2" />
<text  x="464.79" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_8 (82 us., 0.01%)</title><rect x="1122.1" y="85" width="0.1" height="15.0" fill="rgb(229,111,26)" rx="2" ry="2" />
<text  x="1125.08" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_9 (14,716 us., 2.36%)</title><rect x="1146.9" y="117" width="27.9" height="15.0" fill="rgb(207,11,2)" rx="2" ry="2" />
<text  x="1149.93" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (260 us., 0.04%)</title><rect x="1178.8" y="117" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1181.76" y="127.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (80 us., 0.01%)</title><rect x="453.3" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="456.35" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (92 us., 0.01%)</title><rect x="1070.2" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="1073.18" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_42 (799 us., 0.13%)</title><rect x="728.9" y="117" width="1.5" height="15.0" fill="rgb(247,193,46)" rx="2" ry="2" />
<text  x="731.88" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (165 us., 0.03%)</title><rect x="1017.6" y="85" width="0.3" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1020.63" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_12 (927 us., 0.15%)</title><rect x="1015.0" y="117" width="1.8" height="15.0" fill="rgb(216,53,12)" rx="2" ry="2" />
<text  x="1018.03" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (328 us., 0.05%)</title><rect x="906.9" y="85" width="0.6" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="909.88" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (226 us., 0.04%)</title><rect x="515.7" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="518.67" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_60 (4,278 us., 0.69%)</title><rect x="1094.5" y="85" width="8.1" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="1097.53" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (75 us., 0.01%)</title><rect x="965.0" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="967.96" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (211 us., 0.03%)</title><rect x="330.1" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="333.08" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,371 us., 0.38%)</title><rect x="1138.7" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1141.73" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,437 us., 0.55%)</title><rect x="664.3" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="667.29" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (263 us., 0.04%)</title><rect x="731.0" y="85" width="0.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="734.01" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,283 us., 0.69%)</title><rect x="987.3" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="990.27" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (205 us., 0.03%)</title><rect x="602.8" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="605.83" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_18 (4,252 us., 0.68%)</title><rect x="754.8" y="85" width="8.0" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="757.77" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_93 (1,721 us., 0.28%)</title><rect x="269.2" y="85" width="3.3" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="272.23" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (121 us., 0.02%)</title><rect x="907.5" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="910.50" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_107 (1,711 us., 0.27%)</title><rect x="373.9" y="85" width="3.3" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="376.91" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_37 (880 us., 0.14%)</title><rect x="540.4" y="117" width="1.6" height="15.0" fill="rgb(221,75,17)" rx="2" ry="2" />
<text  x="543.37" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (66 us., 0.01%)</title><rect x="312.0" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="314.96" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,261 us., 0.68%)</title><rect x="133.2" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="136.16" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (71 us., 0.01%)</title><rect x="412.2" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="415.21" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (175 us., 0.03%)</title><rect x="413.5" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="416.46" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_10 (10,607 us., 1.70%)</title><rect x="104.8" y="117" width="20.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="107.82" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_126 (1,863 us., 0.30%)</title><rect x="501.1" y="85" width="3.6" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="504.13" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (315 us., 0.05%)</title><rect x="932.0" y="85" width="0.6" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="935.04" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,860 us., 0.30%)</title><rect x="544.0" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="547.02" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,326 us., 0.37%)</title><rect x="220.6" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="223.64" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,754 us., 0.76%)</title><rect x="486.9" y="69" width="9.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="489.85" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,327 us., 0.37%)</title><rect x="209.7" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="212.68" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsub_of_type_object_at_0x7b66dec9e9c0&gt; (67 us., 0.01%)</title><rect x="1180.7" y="69" width="0.2" height="15.0" fill="rgb(244,179,43)" rx="2" ry="2" />
<text  x="1183.74" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (213 us., 0.03%)</title><rect x="173.6" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="176.56" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_41 (796 us., 0.13%)</title><rect x="687.9" y="117" width="1.5" height="15.0" fill="rgb(253,223,53)" rx="2" ry="2" />
<text  x="690.92" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (267 us., 0.04%)</title><rect x="362.5" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="365.45" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_71 (1,726 us., 0.28%)</title><rect x="110.6" y="85" width="3.3" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="113.61" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (816 us., 0.13%)</title><rect x="206.3" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="209.25" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,782 us., 0.29%)</title><rect x="1079.9" y="69" width="3.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1082.89" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_30 (857 us., 0.14%)</title><rect x="411.4" y="117" width="1.6" height="15.0" fill="rgb(216,53,12)" rx="2" ry="2" />
<text  x="414.38" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_15 (26,416 us., 4.24%)</title><rect x="364.5" y="149" width="50.1" height="15.0" fill="rgb(250,210,50)" rx="2" ry="2" />
<text  x="367.52" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (66 us., 0.01%)</title><rect x="153.6" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="156.59" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_73 (2,334 us., 0.37%)</title><rect x="117.1" y="85" width="4.5" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="120.14" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_22 (1,736 us., 0.28%)</title><rect x="792.4" y="85" width="3.3" height="15.0" fill="rgb(235,140,33)" rx="2" ry="2" />
<text  x="795.39" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,259 us., 0.20%)</title><rect x="507.1" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="510.09" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,327 us., 0.37%)</title><rect x="209.7" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="212.68" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_150 (1,858 us., 0.30%)</title><rect x="699.4" y="85" width="3.6" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="702.43" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (826 us., 0.13%)</title><rect x="361.4" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="364.39" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (5,501 us., 0.88%)</title><rect x="78.9" y="69" width="10.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="81.95" y="79.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (85 us., 0.01%)</title><rect x="582.0" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="585.01" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,723 us., 0.28%)</title><rect x="113.9" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="116.88" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,299 us., 0.69%)</title><rect x="807.5" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="810.46" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,793 us., 3.66%)</title><rect x="542.0" y="133" width="43.2" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="545.04" y="143.5" >tran..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,964 us., 4.49%)</title><rect x="965.6" y="133" width="53.0" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="968.61" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_tile_of_Tensor_object_at_0x7b6685adf880&gt; (72 us., 0.01%)</title><rect x="15.7" y="213" width="0.1" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="18.67" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (268 us., 0.04%)</title><rect x="1177.0" y="85" width="0.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1180.03" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (270 us., 0.04%)</title><rect x="688.9" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="691.92" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,216 us., 0.52%)</title><rect x="48.8" y="53" width="6.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="51.76" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (229 us., 0.04%)</title><rect x="332.9" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="335.89" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (170 us., 0.03%)</title><rect x="311.6" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="314.64" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_7 (3,088 us., 0.50%)</title><rect x="837.6" y="117" width="5.8" height="15.0" fill="rgb(250,210,50)" rx="2" ry="2" />
<text  x="840.56" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,713 us., 0.27%)</title><rect x="314.7" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="317.74" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_24 (2,335 us., 0.37%)</title><rect x="799.3" y="85" width="4.4" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="802.31" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (796 us., 0.13%)</title><rect x="687.9" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="690.92" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_14 (847 us., 0.14%)</title><rect x="1070.4" y="117" width="1.6" height="15.0" fill="rgb(253,223,53)" rx="2" ry="2" />
<text  x="1073.35" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (126 us., 0.02%)</title><rect x="366.0" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="369.01" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (171 us., 0.03%)</title><rect x="644.2" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="647.19" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (256 us., 0.04%)</title><rect x="384.4" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="387.44" y="63.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (221 us., 0.04%)</title><rect x="983.8" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="986.75" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (214 us., 0.03%)</title><rect x="874.2" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="877.17" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (287 us., 0.05%)</title><rect x="585.9" y="85" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="588.88" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_48 (6,028 us., 0.97%)</title><rect x="1003.4" y="85" width="11.5" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="1006.44" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (275 us., 0.04%)</title><rect x="1071.4" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1074.43" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_115 (1,869 us., 0.30%)</title><rect x="424.5" y="85" width="3.6" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="427.51" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (453 us., 0.07%)</title><rect x="931.2" y="53" width="0.8" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="934.18" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Embedding_0 (125 us., 0.02%)</title><rect x="46.7" y="149" width="0.2" height="15.0" fill="rgb(235,138,33)" rx="2" ry="2" />
<text  x="49.71" y="159.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_83 (6,032 us., 0.97%)</title><rect x="193.1" y="85" width="11.4" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="196.09" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_17 (82 us., 0.01%)</title><rect x="495.9" y="85" width="0.1" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="498.86" y="95.5" ></text>
</g>
<g >
<title>transformers/generation/logits_process.py(71):___call__ (2,871 us., 0.46%)</title><rect x="1183.0" y="213" width="5.4" height="15.0" fill="rgb(222,78,18)" rx="2" ry="2" />
<text  x="1186.00" y="223.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (211 us., 0.03%)</title><rect x="330.1" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="333.08" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_123 (3,443 us., 0.55%)</title><rect x="473.8" y="85" width="6.5" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="476.80" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_22 (832 us., 0.13%)</title><rect x="204.7" y="117" width="1.6" height="15.0" fill="rgb(210,23,5)" rx="2" ry="2" />
<text  x="207.68" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (73 us., 0.01%)</title><rect x="963.1" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="966.06" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (295 us., 0.05%)</title><rect x="470.1" y="69" width="0.6" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="473.15" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_51 (1,818 us., 0.29%)</title><rect x="1031.0" y="85" width="3.5" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="1034.03" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_50 (1,828 us., 0.29%)</title><rect x="1027.6" y="85" width="3.4" height="15.0" fill="rgb(229,110,26)" rx="2" ry="2" />
<text  x="1030.57" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (70 us., 0.01%)</title><rect x="731.6" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="734.65" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,422 us., 0.39%)</title><rect x="157.7" y="69" width="4.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="160.66" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (190 us., 0.03%)</title><rect x="733.0" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="736.02" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_5 (84 us., 0.01%)</title><rect x="960.4" y="85" width="0.1" height="15.0" fill="rgb(248,201,48)" rx="2" ry="2" />
<text  x="963.36" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_145 (3,436 us., 0.55%)</title><rect x="670.8" y="85" width="6.5" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="673.79" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (85 us., 0.01%)</title><rect x="204.5" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="207.51" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,263 us., 0.68%)</title><rect x="1050.7" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1053.71" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (64 us., 0.01%)</title><rect x="729.7" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="732.65" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_85 (1,732 us., 0.28%)</title><rect x="214.1" y="85" width="3.3" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="217.08" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_116 (3,450 us., 0.55%)</title><rect x="431.3" y="85" width="6.5" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="434.29" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,843 us., 1.74%)</title><rect x="156.2" y="101" width="20.6" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="159.24" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,730 us., 0.28%)</title><rect x="599.6" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="602.55" y="79.5" ></text>
</g>
<g >
<title>ipykernel/ipkernel.py(302):_do_execute (623,012 us., 100.00%)</title><rect x="10.0" y="405" width="1180.0" height="15.0" fill="rgb(212,35,8)" rx="2" ry="2" />
<text  x="13.00" y="415.5" >ipykernel/ipkernel.py(302):_do_execute</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (16,162 us., 2.59%)</title><rect x="16.1" y="165" width="30.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="19.10" y="175.5" >to..</text>
</g>
<g >
<title>IPython/core/interactiveshell.py(2975):_run_cell (623,012 us., 100.00%)</title><rect x="10.0" y="373" width="1180.0" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="13.00" y="383.5" >IPython/core/interactiveshell.py(2975):_run_cell</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="964.8" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="967.83" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (943 us., 0.15%)</title><rect x="1124.0" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1127.02" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,450 us., 0.55%)</title><rect x="431.3" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="434.29" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,320 us., 0.21%)</title><rect x="1039.5" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="1042.50" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (813 us., 0.13%)</title><rect x="152.8" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="155.81" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (120 us., 0.02%)</title><rect x="157.4" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="160.44" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (225 us., 0.04%)</title><rect x="208.9" y="85" width="0.5" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="211.94" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,872 us., 1.75%)</title><rect x="260.0" y="101" width="20.6" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="262.98" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (190 us., 0.03%)</title><rect x="1072.4" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1075.43" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_21 (11,802 us., 1.89%)</title><rect x="706.5" y="117" width="22.4" height="15.0" fill="rgb(236,143,34)" rx="2" ry="2" />
<text  x="709.53" y="127.5" >n..</text>
</g>
<g >
<title>nn.Module:_Linear_9 (1,730 us., 0.28%)</title><rect x="599.6" y="85" width="3.2" height="15.0" fill="rgb(213,38,9)" rx="2" ry="2" />
<text  x="602.55" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,275 us., 0.20%)</title><rect x="652.3" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="655.29" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_102 (4,352 us., 0.70%)</title><rect x="333.5" y="85" width="8.2" height="15.0" fill="rgb(231,123,29)" rx="2" ry="2" />
<text  x="336.50" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="1179.4" y="117" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1182.38" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_111 (4,985 us., 0.80%)</title><rect x="401.8" y="85" width="9.4" height="15.0" fill="rgb(231,123,29)" rx="2" ry="2" />
<text  x="404.78" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (92 us., 0.01%)</title><rect x="1070.2" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="1073.18" y="47.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_16 (940 us., 0.15%)</title><rect x="1122.2" y="117" width="1.8" height="15.0" fill="rgb(240,164,39)" rx="2" ry="2" />
<text  x="1125.24" y="127.5" ></text>
</g>
<g >
<title>runpy.py(86):__run_code (623,012 us., 100.00%)</title><rect x="10.0" y="757" width="1180.0" height="15.0" fill="rgb(245,187,44)" rx="2" ry="2" />
<text  x="13.00" y="767.5" >runpy.py(86):__run_code</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,861 us., 0.30%)</title><rect x="509.5" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="512.48" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_2 (14,727 us., 2.36%)</title><rect x="754.6" y="117" width="27.9" height="15.0" fill="rgb(252,219,52)" rx="2" ry="2" />
<text  x="757.61" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (224 us., 0.04%)</title><rect x="663.7" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="666.71" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,366 us., 0.70%)</title><rect x="280.7" y="69" width="8.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="283.75" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_3 (2,345 us., 0.38%)</title><rect x="61.4" y="85" width="4.4" height="15.0" fill="rgb(252,216,51)" rx="2" ry="2" />
<text  x="64.40" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_7 (2,371 us., 0.38%)</title><rect x="591.7" y="85" width="4.5" height="15.0" fill="rgb(226,97,23)" rx="2" ry="2" />
<text  x="594.73" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,023 us., 0.97%)</title><rect x="949.0" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="951.95" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(1080):_prepare_inputs_for_generation (486 us., 0.08%)</title><rect x="1188.7" y="213" width="0.9" height="15.0" fill="rgb(211,27,6)" rx="2" ry="2" />
<text  x="1191.73" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (62 us., 0.01%)</title><rect x="1072.8" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1075.79" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_37 (1,739 us., 0.28%)</title><rect x="919.9" y="85" width="3.3" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="922.88" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,249 us., 0.52%)</title><rect x="913.7" y="69" width="6.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="916.73" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,371 us., 0.38%)</title><rect x="1138.7" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1141.73" y="63.5" ></text>
</g>
<g >
<title>transformers/generation/utils.py(735):__expand_dict_for_generation (85 us., 0.01%)</title><rect x="1189.8" y="213" width="0.2" height="15.0" fill="rgb(214,42,10)" rx="2" ry="2" />
<text  x="1192.84" y="223.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_16 (11,816 us., 1.90%)</title><rect x="431.1" y="117" width="22.4" height="15.0" fill="rgb(210,24,5)" rx="2" ry="2" />
<text  x="434.12" y="127.5" >n..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (940 us., 0.15%)</title><rect x="1122.2" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1125.24" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_4 (92 us., 0.01%)</title><rect x="902.4" y="85" width="0.2" height="15.0" fill="rgb(205,0,0)" rx="2" ry="2" />
<text  x="905.43" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_146 (4,742 us., 0.76%)</title><rect x="677.3" y="85" width="9.0" height="15.0" fill="rgb(230,115,27)" rx="2" ry="2" />
<text  x="680.30" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (464 us., 0.07%)</title><rect x="604.8" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="607.83" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (216 us., 0.03%)</title><rect x="228.0" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="231.00" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_128 (1,259 us., 0.20%)</title><rect x="507.1" y="85" width="2.4" height="15.0" fill="rgb(230,115,27)" rx="2" ry="2" />
<text  x="510.09" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2109):_embedding (125 us., 0.02%)</title><rect x="46.7" y="117" width="0.2" height="15.0" fill="rgb(206,7,1)" rx="2" ry="2" />
<text  x="49.71" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,273 us., 0.20%)</title><rect x="330.5" y="85" width="2.4" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="333.48" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (128 us., 0.02%)</title><rect x="1022.9" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1025.91" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_3 (91 us., 0.01%)</title><rect x="835.3" y="85" width="0.2" height="15.0" fill="rgb(211,30,7)" rx="2" ry="2" />
<text  x="838.29" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (198 us., 0.03%)</title><rect x="381.8" y="85" width="0.3" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="384.77" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_35 (3,166 us., 0.51%)</title><rect x="907.7" y="85" width="6.0" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="910.73" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (14,713 us., 2.36%)</title><rect x="846.7" y="101" width="27.9" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="849.71" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,439 us., 0.55%)</title><rect x="566.3" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="569.31" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (457 us., 0.07%)</title><rect x="69.4" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="72.38" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (286 us., 0.05%)</title><rect x="646.3" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="649.28" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_44 (2,254 us., 0.36%)</title><rect x="975.0" y="85" width="4.3" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="978.05" y="95.5" ></text>
</g>
<g >
<title>ipykernel/kernelapp.py(619):_start (623,012 us., 100.00%)</title><rect x="10.0" y="709" width="1180.0" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="13.00" y="719.5" >ipykernel/kernelapp.py(619):_start</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,424 us., 0.55%)</title><rect x="706.7" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="709.69" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mul_of_Tensor_object_at_0x7b66858401d0&gt; (68 us., 0.01%)</title><rect x="11.2" y="213" width="0.1" height="15.0" fill="rgb(251,214,51)" rx="2" ry="2" />
<text  x="14.19" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (60 us., 0.01%)</title><rect x="688.7" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="691.67" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,330 us., 0.21%)</title><rect x="984.2" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="987.17" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_141 (1,275 us., 0.20%)</title><rect x="652.3" y="85" width="2.4" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="655.29" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (270 us., 0.04%)</title><rect x="965.1" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="968.10" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_10 (1,765 us., 0.28%)</title><rect x="960.5" y="117" width="3.4" height="15.0" fill="rgb(229,112,26)" rx="2" ry="2" />
<text  x="963.52" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,436 us., 0.55%)</title><rect x="670.8" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="673.79" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (190 us., 0.03%)</title><rect x="208.6" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="211.55" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,725 us., 2.36%)</title><rect x="1042.5" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="1045.46" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (352 us., 0.06%)</title><rect x="1126.9" y="85" width="0.7" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="1129.89" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,957 us., 0.47%)</title><rect x="855.8" y="69" width="5.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="858.85" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (169 us., 0.03%)</title><rect x="101.6" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="104.61" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (8,578 us., 1.38%)</title><rect x="414.9" y="101" width="16.2" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="417.87" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_47 (4,255 us., 0.68%)</title><rect x="995.4" y="85" width="8.0" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="998.38" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaModel_0 (598,806 us., 96.11%)</title><rect x="46.7" y="181" width="1134.2" height="15.0" fill="rgb(210,23,5)" rx="2" ry="2" />
<text  x="49.71" y="191.5" >nn.Module:_LlamaModel_0</text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (174 us., 0.03%)</title><rect x="904.7" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="907.67" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (255 us., 0.04%)</title><rect x="332.4" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="335.41" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_1 (10,871 us., 1.74%)</title><rect x="585.5" y="117" width="20.6" height="15.0" fill="rgb(227,103,24)" rx="2" ry="2" />
<text  x="588.54" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,014 us., 0.97%)</title><rect x="1058.8" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1061.79" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (998 us., 0.16%)</title><rect x="538.5" y="101" width="1.9" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="541.48" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (216 us., 0.03%)</title><rect x="473.2" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="476.23" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_86 (1,728 us., 0.28%)</title><rect x="217.4" y="85" width="3.2" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="220.36" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_58 (1,723 us., 0.28%)</title><rect x="1083.3" y="85" width="3.2" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1086.27" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="256.1" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="259.15" y="47.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="100.9" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="103.94" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,723 us., 0.28%)</title><rect x="1083.3" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1086.27" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_109 (4,311 us., 0.69%)</title><rect x="385.5" y="85" width="8.2" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="388.51" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_15 (10,836 us., 1.74%)</title><rect x="364.8" y="117" width="20.6" height="15.0" fill="rgb(235,138,33)" rx="2" ry="2" />
<text  x="367.83" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_32 (4,360 us., 0.70%)</title><rect x="874.7" y="85" width="8.3" height="15.0" fill="rgb(229,110,26)" rx="2" ry="2" />
<text  x="877.73" y="95.5" ></text>
</g>
<g >
<title>tornado/gen.py(786):_run (623,012 us., 100.00%)</title><rect x="10.0" y="581" width="1180.0" height="15.0" fill="rgb(245,187,44)" rx="2" ry="2" />
<text  x="13.00" y="591.5" >tornado/gen.py(786):_run</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_5 (965 us., 0.15%)</title><rect x="784.1" y="117" width="1.9" height="15.0" fill="rgb(213,39,9)" rx="2" ry="2" />
<text  x="787.14" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,105 us., 0.18%)</title><rect x="835.5" y="101" width="2.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="838.47" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_77 (2,422 us., 0.39%)</title><rect x="157.7" y="85" width="4.6" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="160.66" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (192 us., 0.03%)</title><rect x="313.7" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="316.70" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,732 us., 0.28%)</title><rect x="214.1" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="217.08" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,261 us., 0.68%)</title><rect x="133.2" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="136.16" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="495.9" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="498.86" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,957 us., 0.47%)</title><rect x="855.8" y="53" width="5.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="858.85" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,244 us., 0.68%)</title><rect x="1102.6" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1105.63" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (177 us., 0.03%)</title><rect x="903.1" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="906.07" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="363.7" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="366.74" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_69 (6,031 us., 0.97%)</title><rect x="1163.2" y="85" width="11.4" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="1166.22" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (224 us., 0.04%)</title><rect x="663.7" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="666.71" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_5 (5,501 us., 0.88%)</title><rect x="78.9" y="85" width="10.5" height="15.0" fill="rgb(239,156,37)" rx="2" ry="2" />
<text  x="81.95" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_new_ones_of_Tensor_object_at_0x7b6685841210&gt; (64 us., 0.01%)</title><rect x="1188.6" y="197" width="0.1" height="15.0" fill="rgb(207,10,2)" rx="2" ry="2" />
<text  x="1191.61" y="207.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_103 (4,261 us., 0.68%)</title><rect x="341.7" y="85" width="8.1" height="15.0" fill="rgb(225,93,22)" rx="2" ry="2" />
<text  x="344.74" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,737 us., 0.28%)</title><rect x="852.6" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="855.56" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_7 (92 us., 0.01%)</title><rect x="1070.2" y="85" width="0.2" height="15.0" fill="rgb(235,141,33)" rx="2" ry="2" />
<text  x="1073.18" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (203 us., 0.03%)</title><rect x="428.1" y="85" width="0.3" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="431.05" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_11 (14,728 us., 2.36%)</title><rect x="176.8" y="117" width="27.9" height="15.0" fill="rgb(242,172,41)" rx="2" ry="2" />
<text  x="179.78" y="127.5" >n..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (461 us., 0.07%)</title><rect x="1093.1" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="1096.09" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (216 us., 0.03%)</title><rect x="473.2" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="476.23" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,360 us., 0.70%)</title><rect x="874.7" y="53" width="8.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="877.73" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (85 us., 0.01%)</title><rect x="204.5" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="207.51" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,254 us., 0.68%)</title><rect x="1147.1" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1150.09" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (172 us., 0.03%)</title><rect x="309.4" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="312.44" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,449 us., 0.55%)</title><rect x="559.8" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="562.78" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,014 us., 0.97%)</title><rect x="891.0" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="894.04" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (29,044 us., 4.66%)</title><rect x="1018.6" y="133" width="55.0" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="1021.58" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="152.7" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="155.65" y="47.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,329 us., 0.37%)</title><rect x="848.1" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="851.15" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,896 us., 2.39%)</title><rect x="280.6" y="101" width="28.2" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="283.57" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,726 us., 0.28%)</title><rect x="741.9" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="744.91" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (191 us., 0.03%)</title><rect x="365.2" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="368.20" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (85 us., 0.01%)</title><rect x="411.2" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="414.22" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (448 us., 0.07%)</title><rect x="472.4" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="475.38" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_84 (2,327 us., 0.37%)</title><rect x="209.7" y="85" width="4.4" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="212.68" y="95.5" ></text>
</g>
<g >
<title>transformers/modeling_attn_mask_utils.py(164):__prepare_4d_causal_attention_mask (460 us., 0.07%)</title><rect x="1180.0" y="149" width="0.9" height="15.0" fill="rgb(244,179,42)" rx="2" ry="2" />
<text  x="1182.99" y="159.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (227 us., 0.04%)</title><rect x="966.7" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="969.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (162 us., 0.03%)</title><rect x="729.3" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="732.35" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_100 (1,713 us., 0.27%)</title><rect x="314.7" y="85" width="3.3" height="15.0" fill="rgb(244,183,43)" rx="2" ry="2" />
<text  x="317.74" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,278 us., 0.69%)</title><rect x="1094.5" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1097.53" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,268 us., 0.69%)</title><rect x="125.1" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="128.07" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (224 us., 0.04%)</title><rect x="706.1" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="709.11" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_117 (3,439 us., 0.55%)</title><rect x="437.8" y="85" width="6.5" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="440.82" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (986 us., 0.16%)</title><rect x="65.8" y="69" width="1.9" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="68.84" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,254 us., 0.36%)</title><rect x="975.0" y="69" width="4.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="978.05" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_20 (11,775 us., 1.89%)</title><rect x="664.1" y="117" width="22.3" height="15.0" fill="rgb(242,172,41)" rx="2" ry="2" />
<text  x="667.13" y="127.5" >n..</text>
</g>
<g >
<title>colab_kernel_launcher.py(37):_&lt;module&gt; (623,012 us., 100.00%)</title><rect x="10.0" y="741" width="1180.0" height="15.0" fill="rgb(230,118,28)" rx="2" ry="2" />
<text  x="13.00" y="751.5" >colab_kernel_launcher.py(37):_&lt;module&gt;</text>
</g>
<g >
<title>nn.Module:_SiLUActivation_6 (92 us., 0.01%)</title><rect x="1014.9" y="85" width="0.1" height="15.0" fill="rgb(242,171,40)" rx="2" ry="2" />
<text  x="1017.86" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (121 us., 0.02%)</title><rect x="314.5" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="317.51" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (272 us., 0.04%)</title><rect x="1074.7" y="85" width="0.6" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="1077.74" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cumsum_of_Tensor_object_at_0x7b6685841210&gt; (273 us., 0.04%)</title><rect x="1189.0" y="197" width="0.5" height="15.0" fill="rgb(223,84,20)" rx="2" ry="2" />
<text  x="1192.02" y="207.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (11,177 us., 1.79%)</title><rect x="965.9" y="101" width="21.2" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="968.93" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_99 (1,732 us., 0.28%)</title><rect x="326.8" y="85" width="3.3" height="15.0" fill="rgb(245,184,44)" rx="2" ry="2" />
<text  x="329.80" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,278 us., 0.21%)</title><rect x="694.6" y="53" width="2.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="697.64" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (31,575 us., 5.07%)</title><rect x="905.8" y="133" width="59.8" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="908.81" y="143.5" >transf..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (945 us., 0.15%)</title><rect x="1016.8" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1019.79" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_142 (1,253 us., 0.20%)</title><rect x="654.7" y="85" width="2.4" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="657.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (266 us., 0.04%)</title><rect x="648.1" y="85" width="0.5" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="651.05" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (818 us., 0.13%)</title><rect x="256.3" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="259.30" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_0 (82 us., 0.01%)</title><rect x="100.9" y="85" width="0.2" height="15.0" fill="rgb(231,119,28)" rx="2" ry="2" />
<text  x="103.94" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_1 (2,229 us., 0.36%)</title><rect x="636.4" y="85" width="4.3" height="15.0" fill="rgb(224,89,21)" rx="2" ry="2" />
<text  x="639.44" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_13 (10,872 us., 1.75%)</title><rect x="260.0" y="117" width="20.6" height="15.0" fill="rgb(247,197,47)" rx="2" ry="2" />
<text  x="262.98" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,634 us., 0.26%)</title><rect x="643.7" y="101" width="3.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="646.73" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,863 us., 0.30%)</title><rect x="501.1" y="69" width="3.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="504.13" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (201 us., 0.03%)</title><rect x="1143.2" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="1146.22" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,723 us., 0.28%)</title><rect x="113.9" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="116.88" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_11 (5,506 us., 0.88%)</title><rect x="606.3" y="85" width="10.4" height="15.0" fill="rgb(248,199,47)" rx="2" ry="2" />
<text  x="609.28" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_87 (2,326 us., 0.37%)</title><rect x="220.6" y="85" width="4.4" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="223.64" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (210 us., 0.03%)</title><rect x="803.7" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="806.73" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,277 us., 0.69%)</title><rect x="228.6" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="231.59" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,031 us., 0.97%)</title><rect x="1163.2" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1166.22" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_46 (4,283 us., 0.69%)</title><rect x="987.3" y="85" width="8.1" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="990.27" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (1,068 us., 0.17%)</title><rect x="1181.0" y="197" width="2.0" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="1183.98" y="207.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (203 us., 0.03%)</title><rect x="513.0" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="516.00" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,264 us., 0.20%)</title><rect x="464.2" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="467.20" y="63.5" ></text>
</g>
<g >
<title>tornado/gen.py(234):_wrapper (623,012 us., 100.00%)</title><rect x="10.0" y="485" width="1180.0" height="15.0" fill="rgb(208,16,3)" rx="2" ry="2" />
<text  x="13.00" y="495.5" >tornado/gen.py(234):_wrapper</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,384 us., 0.38%)</title><rect x="923.2" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="926.18" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (219 us., 0.04%)</title><rect x="430.7" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="433.70" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (176 us., 0.03%)</title><rect x="962.7" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="965.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (66 us., 0.01%)</title><rect x="259.0" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="262.02" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_1 (32,532 us., 5.22%)</title><rect x="585.2" y="149" width="61.6" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="588.21" y="159.5" >nn.Mod..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,857 us., 0.30%)</title><rect x="458.3" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="461.28" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (32,532 us., 5.22%)</title><rect x="585.2" y="133" width="61.6" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="588.21" y="143.5" >transf..</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_0 (950 us., 0.15%)</title><rect x="101.1" y="117" width="1.8" height="15.0" fill="rgb(245,188,45)" rx="2" ry="2" />
<text  x="104.10" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (8,860 us., 1.42%)</title><rect x="689.8" y="101" width="16.7" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="692.75" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (241 us., 0.04%)</title><rect x="1042.0" y="85" width="0.5" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="1045.00" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (271 us., 0.04%)</title><rect x="584.7" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="587.70" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (192 us., 0.03%)</title><rect x="847.1" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="850.09" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_8 (1,757 us., 0.28%)</title><rect x="596.2" y="85" width="3.4" height="15.0" fill="rgb(219,67,16)" rx="2" ry="2" />
<text  x="599.23" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_44 (881 us., 0.14%)</title><rect x="1178.3" y="149" width="1.7" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1181.32" y="159.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_149 (1,250 us., 0.20%)</title><rect x="697.1" y="85" width="2.3" height="15.0" fill="rgb(210,26,6)" rx="2" ry="2" />
<text  x="700.06" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsub_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="1180.9" y="181" width="0.1" height="15.0" fill="rgb(244,179,43)" rx="2" ry="2" />
<text  x="1183.86" y="191.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (30,386 us., 4.88%)</title><rect x="46.9" y="133" width="57.6" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="49.95" y="143.5" >transf..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (919 us., 0.15%)</title><rect x="1176.6" y="101" width="1.7" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1179.58" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_17 (2,334 us., 0.37%)</title><rect x="745.2" y="85" width="4.4" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="748.18" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,857 us., 0.30%)</title><rect x="458.3" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="461.28" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,248 us., 0.68%)</title><rect x="883.0" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="885.99" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_5 (31,575 us., 5.07%)</title><rect x="905.8" y="149" width="59.8" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="908.81" y="159.5" >nn.Mod..</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_20 (813 us., 0.13%)</title><rect x="152.8" y="117" width="1.5" height="15.0" fill="rgb(222,82,19)" rx="2" ry="2" />
<text  x="155.81" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (499 us., 0.08%)</title><rect x="123.5" y="69" width="1.0" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="126.55" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,739 us., 0.28%)</title><rect x="919.9" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="922.88" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (220 us., 0.04%)</title><rect x="605.7" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="608.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (170 us., 0.03%)</title><rect x="102.1" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="105.06" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,244 us., 0.68%)</title><rect x="1102.6" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1105.63" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (273 us., 0.04%)</title><rect x="259.1" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="262.14" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_125 (4,754 us., 0.76%)</title><rect x="486.9" y="85" width="9.0" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="489.85" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_13 (6,052 us., 0.97%)</title><rect x="625.0" y="85" width="11.4" height="15.0" fill="rgb(235,140,33)" rx="2" ry="2" />
<text  x="627.98" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (804 us., 0.13%)</title><rect x="453.5" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="456.50" y="111.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (2,229 us., 0.36%)</title><rect x="636.4" y="53" width="4.3" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="639.44" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (261 us., 0.04%)</title><rect x="541.5" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="544.54" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (71 us., 0.01%)</title><rect x="644.5" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="647.52" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (539 us., 0.09%)</title><rect x="662.7" y="69" width="1.0" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="665.69" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_ne_of_Tensor_object_at_0x7b6685852f20&gt; (60 us., 0.01%)</title><rect x="15.2" y="213" width="0.1" height="15.0" fill="rgb(207,11,2)" rx="2" ry="2" />
<text  x="18.20" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,330 us., 0.37%)</title><rect x="261.6" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="264.56" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (458 us., 0.07%)</title><rect x="175.5" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="178.51" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (275 us., 0.04%)</title><rect x="1041.5" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1044.48" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,828 us., 0.29%)</title><rect x="1027.6" y="69" width="3.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1030.57" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (212 us., 0.03%)</title><rect x="836.1" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="839.10" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,721 us., 0.28%)</title><rect x="269.2" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="272.23" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_5 (13,992 us., 2.25%)</title><rect x="906.1" y="117" width="26.5" height="15.0" fill="rgb(251,214,51)" rx="2" ry="2" />
<text  x="909.13" y="127.5" >n..</text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (196 us., 0.03%)</title><rect x="660.8" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="663.81" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,387 us., 4.40%)</title><rect x="155.9" y="133" width="51.9" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="158.93" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (66 us., 0.01%)</title><rect x="205.5" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="208.47" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,728 us., 0.28%)</title><rect x="370.6" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="373.64" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_0 (30,386 us., 4.88%)</title><rect x="46.9" y="149" width="57.6" height="15.0" fill="rgb(249,204,48)" rx="2" ry="2" />
<text  x="49.95" y="159.5" >nn.Mod..</text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (196 us., 0.03%)</title><rect x="660.8" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="663.81" y="79.5" ></text>
</g>
<g >
<title>IPython/core/interactiveshell.py(3257):_run_cell_async (623,012 us., 100.00%)</title><rect x="10.0" y="325" width="1180.0" height="15.0" fill="rgb(211,28,6)" rx="2" ry="2" />
<text  x="13.00" y="335.5" >IPython/core/interactiveshell.py(3257):_run_cell_async</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,332 us., 0.21%)</title><rect x="470.7" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="473.70" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_41 (6,023 us., 0.97%)</title><rect x="949.0" y="85" width="11.4" height="15.0" fill="rgb(229,110,26)" rx="2" ry="2" />
<text  x="951.95" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (220 us., 0.04%)</title><rect x="124.5" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="127.49" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,031 us., 0.97%)</title><rect x="1163.2" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1166.22" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (73 us., 0.01%)</title><rect x="1125.0" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1127.99" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (3,088 us., 0.50%)</title><rect x="837.6" y="101" width="5.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="840.56" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,323 us., 0.37%)</title><rect x="106.2" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="109.21" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (72 us., 0.01%)</title><rect x="731.5" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="734.51" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_31 (821 us., 0.13%)</title><rect x="413.0" y="117" width="1.6" height="15.0" fill="rgb(210,23,5)" rx="2" ry="2" />
<text  x="416.00" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,330 us., 0.37%)</title><rect x="1086.5" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1089.53" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (847 us., 0.14%)</title><rect x="102.9" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="105.89" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (177 us., 0.03%)</title><rect x="1124.7" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1127.66" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,665 us., 3.64%)</title><rect x="456.5" y="133" width="43.0" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="459.55" y="143.5" >tran..</text>
</g>
<g >
<title>nn.Module:_Linear_75 (4,261 us., 0.68%)</title><rect x="133.2" y="85" width="8.0" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="136.16" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,836 us., 1.74%)</title><rect x="364.8" y="101" width="20.6" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="367.83" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (91 us., 0.01%)</title><rect x="835.3" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="838.29" y="47.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (965 us., 0.15%)</title><rect x="784.1" y="101" width="1.9" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="787.14" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (857 us., 0.14%)</title><rect x="411.4" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="414.38" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (172 us., 0.03%)</title><rect x="784.7" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="787.69" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (263 us., 0.04%)</title><rect x="687.4" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="690.42" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (266 us., 0.04%)</title><rect x="1015.5" y="85" width="0.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1018.49" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,329 us., 0.37%)</title><rect x="848.1" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="851.15" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (231 us., 0.04%)</title><rect x="806.9" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="809.85" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,726 us., 0.28%)</title><rect x="110.6" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="113.61" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,450 us., 0.55%)</title><rect x="431.3" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="434.29" y="63.5" ></text>
</g>
<g >
<title>ipykernel/kernelbase.py(377):_dispatch_queue (623,012 us., 100.00%)</title><rect x="10.0" y="565" width="1180.0" height="15.0" fill="rgb(247,196,47)" rx="2" ry="2" />
<text  x="13.00" y="575.5" >ipykernel/kernelbase.py(377):_dispatch_queue</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,273 us., 0.20%)</title><rect x="419.7" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="422.72" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_20 (6,045 us., 0.97%)</title><rect x="770.9" y="85" width="11.5" height="15.0" fill="rgb(248,199,47)" rx="2" ry="2" />
<text  x="773.90" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,250 us., 0.20%)</title><rect x="697.1" y="53" width="2.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="700.06" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (324 us., 0.05%)</title><rect x="1146.3" y="85" width="0.6" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="1149.32" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (80 us., 0.01%)</title><rect x="686.3" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="689.28" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (324 us., 0.05%)</title><rect x="1146.3" y="69" width="0.6" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="1149.32" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,306 us., 0.69%)</title><rect x="289.0" y="69" width="8.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="292.02" y="79.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (87 us., 0.01%)</title><rect x="538.3" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="541.32" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (276 us., 0.04%)</title><rect x="1176.1" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1179.06" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,704 us., 0.27%)</title><rect x="1135.5" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1138.51" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,330 us., 0.37%)</title><rect x="318.0" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="320.99" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,389 us., 0.22%)</title><rect x="1091.3" y="85" width="2.7" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="1094.33" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_4 (860 us., 0.14%)</title><rect x="782.5" y="117" width="1.6" height="15.0" fill="rgb(220,69,16)" rx="2" ry="2" />
<text  x="785.51" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,259 us., 0.20%)</title><rect x="507.1" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="510.09" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (273 us., 0.04%)</title><rect x="783.6" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="786.62" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (261 us., 0.04%)</title><rect x="539.1" y="85" width="0.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="542.11" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,367 us., 0.70%)</title><rect x="815.6" y="53" width="8.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="818.60" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_114 (1,257 us., 0.20%)</title><rect x="422.1" y="85" width="2.4" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="425.13" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_38 (2,384 us., 0.38%)</title><rect x="923.2" y="85" width="4.5" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="926.18" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="152.7" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="155.65" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (67 us., 0.01%)</title><rect x="1125.1" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1128.13" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,266 us., 0.68%)</title><rect x="932.8" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="935.81" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_20 (80 us., 0.01%)</title><rect x="686.3" y="85" width="0.1" height="15.0" fill="rgb(208,13,3)" rx="2" ry="2" />
<text  x="689.28" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,853 us., 0.30%)</title><rect x="648.8" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="651.78" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (652 us., 0.10%)</title><rect x="930.8" y="69" width="1.2" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="933.80" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,861 us., 0.30%)</title><rect x="509.5" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="512.48" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,255 us., 0.68%)</title><rect x="995.4" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="998.38" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_8 (27,570 us., 4.43%)</title><rect x="1073.6" y="149" width="52.2" height="15.0" fill="rgb(247,197,47)" rx="2" ry="2" />
<text  x="1076.59" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (455 us., 0.07%)</title><rect x="279.1" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="282.11" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_134 (1,274 us., 0.20%)</title><rect x="547.5" y="85" width="2.5" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="550.54" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_6 (6,111 us., 0.98%)</title><rect x="89.4" y="85" width="11.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="92.37" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_30 (2,957 us., 0.47%)</title><rect x="855.8" y="85" width="5.6" height="15.0" fill="rgb(241,169,40)" rx="2" ry="2" />
<text  x="858.85" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (805 us., 0.13%)</title><rect x="455.0" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="458.02" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,031 us., 0.97%)</title><rect x="823.9" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="826.87" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_124 (3,445 us., 0.55%)</title><rect x="480.3" y="85" width="6.6" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="483.33" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_131 (3,447 us., 0.55%)</title><rect x="522.8" y="85" width="6.5" height="15.0" fill="rgb(218,64,15)" rx="2" ry="2" />
<text  x="525.78" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (84 us., 0.01%)</title><rect x="960.4" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="963.36" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,829 us., 0.29%)</title><rect x="162.3" y="69" width="3.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="165.25" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,437 us., 0.23%)</title><rect x="804.1" y="85" width="2.8" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="807.13" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,257 us., 0.20%)</title><rect x="422.1" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="425.13" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (192 us., 0.03%)</title><rect x="500.1" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="503.14" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,273 us., 0.20%)</title><rect x="419.7" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="422.72" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (8,877 us., 1.42%)</title><rect x="647.3" y="101" width="16.8" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="650.32" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (5,506 us., 0.88%)</title><rect x="606.3" y="53" width="10.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="609.28" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (68 us., 0.01%)</title><rect x="584.6" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="587.57" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_14 (14,820 us., 2.38%)</title><rect x="333.3" y="117" width="28.1" height="15.0" fill="rgb(223,83,20)" rx="2" ry="2" />
<text  x="336.33" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (172 us., 0.03%)</title><rect x="258.6" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="261.58" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_10 (27,152 us., 4.36%)</title><rect x="104.5" y="149" width="51.4" height="15.0" fill="rgb(232,128,30)" rx="2" ry="2" />
<text  x="107.50" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,342 us., 0.38%)</title><rect x="272.5" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="275.49" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_108 (2,438 us., 0.39%)</title><rect x="377.2" y="85" width="4.6" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="380.15" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,853 us., 0.78%)</title><rect x="572.8" y="53" width="9.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="575.82" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (8,863 us., 1.42%)</title><rect x="456.8" y="101" width="16.8" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="459.85" y="111.5" ></text>
</g>
<g >
<title>IPython/core/interactiveshell.py(3473):_run_ast_nodes (623,012 us., 100.00%)</title><rect x="10.0" y="309" width="1180.0" height="15.0" fill="rgb(211,31,7)" rx="2" ry="2" />
<text  x="13.00" y="319.5" >IPython/core/interactiveshell.py(3473):_run_ast_nodes</text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (173 us., 0.03%)</title><rect x="154.8" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="157.84" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (161 us., 0.03%)</title><rect x="842.6" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="845.57" y="95.5" ></text>
</g>
<g >
<title>ipykernel/kernelbase.py(361):_process_one (623,012 us., 100.00%)</title><rect x="10.0" y="501" width="1180.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="13.00" y="511.5" >ipykernel/kernelbase.py(361):_process_one</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,028 us., 0.97%)</title><rect x="1003.4" y="69" width="11.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1006.44" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,027 us., 0.97%)</title><rect x="297.2" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="300.17" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,756 us., 0.76%)</title><rect x="529.3" y="53" width="9.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="532.31" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (184 us., 0.03%)</title><rect x="1074.4" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1077.37" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,816 us., 1.90%)</title><rect x="431.1" y="101" width="22.4" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="434.12" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,254 us., 0.68%)</title><rect x="1147.1" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1150.09" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_4 (32,945 us., 5.29%)</title><rect x="843.4" y="149" width="62.4" height="15.0" fill="rgb(223,85,20)" rx="2" ry="2" />
<text  x="846.41" y="159.5" >nn.Mod..</text>
</g>
<g >
<title>asyncio/base_events.py(1909):__run_once (623,012 us., 100.00%)</title><rect x="10.0" y="661" width="1180.0" height="15.0" fill="rgb(247,197,47)" rx="2" ry="2" />
<text  x="13.00" y="671.5" >asyncio/base_events.py(1909):__run_once</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,285 us., 0.21%)</title><rect x="504.7" y="53" width="2.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="507.66" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (60 us., 0.01%)</title><rect x="687.2" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="690.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (207 us., 0.03%)</title><rect x="415.6" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="418.59" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (265 us., 0.04%)</title><rect x="456.0" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="459.04" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (92 us., 0.01%)</title><rect x="902.4" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="905.43" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,969 us., 0.32%)</title><rect x="657.1" y="53" width="3.7" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="660.08" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,409 us., 0.23%)</title><rect x="556.5" y="85" width="2.7" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="559.53" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (85 us., 0.01%)</title><rect x="582.0" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="585.01" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (86 us., 0.01%)</title><rect x="1174.6" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="1177.64" y="47.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,871 us., 1.74%)</title><rect x="585.5" y="101" width="20.6" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="588.54" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (169 us., 0.03%)</title><rect x="206.7" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="209.72" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_2 (1,618 us., 0.26%)</title><rect x="640.7" y="117" width="3.0" height="15.0" fill="rgb(233,129,30)" rx="2" ry="2" />
<text  x="643.67" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="782.4" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="785.35" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,860 us., 0.30%)</title><rect x="544.0" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="547.02" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (189 us., 0.03%)</title><rect x="105.2" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="108.17" y="95.5" ></text>
</g>
<g >
<title>tornado/ioloop.py(685):_&lt;lambda&gt; (623,012 us., 100.00%)</title><rect x="10.0" y="629" width="1180.0" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="13.00" y="639.5" >tornado/ioloop.py(685):_&lt;lambda&gt;</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (28,331 us., 4.55%)</title><rect x="732.3" y="133" width="53.7" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="735.30" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (62 us., 0.01%)</title><rect x="905.0" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="908.00" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (74 us., 0.01%)</title><rect x="1177.5" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1180.53" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,617 us., 0.58%)</title><rect x="861.4" y="53" width="6.9" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="864.45" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (198 us., 0.03%)</title><rect x="225.0" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="228.04" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (13,740 us., 2.21%)</title><rect x="385.4" y="101" width="26.0" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="388.35" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="842.4" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="845.44" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,439 us., 0.55%)</title><rect x="437.8" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="440.82" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (263 us., 0.04%)</title><rect x="583.2" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="586.17" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,248 us., 0.68%)</title><rect x="883.0" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="885.99" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_9 (27,729 us., 4.45%)</title><rect x="1125.8" y="149" width="52.5" height="15.0" fill="rgb(241,167,40)" rx="2" ry="2" />
<text  x="1128.80" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (84 us., 0.01%)</title><rect x="960.4" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="963.36" y="47.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,368 us., 0.70%)</title><rect x="616.7" y="69" width="8.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="619.71" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_80 (2,332 us., 0.37%)</title><rect x="169.1" y="85" width="4.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="172.15" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (847 us., 0.14%)</title><rect x="1070.4" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1073.35" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,813 us., 1.90%)</title><rect x="473.6" y="101" width="22.4" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="476.64" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,323 us., 0.37%)</title><rect x="322.4" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="325.40" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (255 us., 0.04%)</title><rect x="175.9" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="178.89" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,257 us., 0.20%)</title><rect x="422.1" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="425.13" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,152 us., 4.36%)</title><rect x="104.5" y="133" width="51.4" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="107.50" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (237 us., 0.04%)</title><rect x="690.5" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="693.46" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (64 us., 0.01%)</title><rect x="496.8" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="499.77" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_12 (14,726 us., 2.36%)</title><rect x="228.4" y="117" width="27.9" height="15.0" fill="rgb(236,143,34)" rx="2" ry="2" />
<text  x="231.41" y="127.5" >n..</text>
</g>
<g >
<title>nn.Module:_Linear_104 (6,029 us., 0.97%)</title><rect x="349.8" y="85" width="11.4" height="15.0" fill="rgb(218,64,15)" rx="2" ry="2" />
<text  x="352.81" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (258 us., 0.04%)</title><rect x="279.5" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="282.48" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (832 us., 0.13%)</title><rect x="154.3" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="157.35" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (263 us., 0.04%)</title><rect x="605.2" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="608.21" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,334 us., 0.37%)</title><rect x="1023.1" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1026.15" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (12,348 us., 1.98%)</title><rect x="47.3" y="101" width="23.4" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="50.28" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (296 us., 0.05%)</title><rect x="786.6" y="85" width="0.6" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="789.64" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="728.7" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="731.73" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (168 us., 0.03%)</title><rect x="205.2" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="208.15" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,335 us., 0.37%)</title><rect x="799.3" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="802.31" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,283 us., 0.69%)</title><rect x="987.3" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="990.27" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_90 (6,021 us., 0.97%)</title><rect x="244.7" y="85" width="11.4" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="247.75" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,262 us., 0.20%)</title><rect x="550.0" y="69" width="2.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="552.96" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (268 us., 0.04%)</title><rect x="414.0" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="417.05" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (208 us., 0.03%)</title><rect x="703.0" y="85" width="0.3" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="705.95" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,342 us., 0.38%)</title><rect x="979.3" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="982.31" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,728 us., 0.28%)</title><rect x="738.6" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="741.64" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (281 us., 0.05%)</title><rect x="903.7" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="906.67" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,726 us., 0.28%)</title><rect x="741.9" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="744.91" y="63.5" ></text>
</g>
<g >
<title>torch/_tensor.py(33):_wrapped (60 us., 0.01%)</title><rect x="1180.9" y="213" width="0.1" height="15.0" fill="rgb(223,84,20)" rx="2" ry="2" />
<text  x="1183.86" y="223.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_9 (10,987 us., 1.76%)</title><rect x="1126.1" y="117" width="20.8" height="15.0" fill="rgb(225,95,22)" rx="2" ry="2" />
<text  x="1129.12" y="127.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="100.9" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="103.94" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,319 us., 0.37%)</title><rect x="366.2" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="369.25" y="63.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (86 us., 0.01%)</title><rect x="1174.6" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1177.64" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (254 us., 0.04%)</title><rect x="558.7" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="561.72" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,757 us., 0.28%)</title><rect x="596.2" y="69" width="3.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="599.23" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (2,229 us., 0.36%)</title><rect x="636.4" y="37" width="4.3" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="639.44" y="47.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,021 us., 0.97%)</title><rect x="244.7" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="247.75" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (784 us., 0.13%)</title><rect x="686.4" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="689.44" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_0 (3,216 us., 0.52%)</title><rect x="48.8" y="85" width="6.0" height="15.0" fill="rgb(221,75,18)" rx="2" ry="2" />
<text  x="51.76" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_7 (29,044 us., 4.66%)</title><rect x="1018.6" y="149" width="55.0" height="15.0" fill="rgb(254,226,54)" rx="2" ry="2" />
<text  x="1021.58" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,728 us., 0.28%)</title><rect x="54.8" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="57.85" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,033 us., 0.97%)</title><rect x="141.2" y="69" width="11.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="144.23" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (90 us., 0.01%)</title><rect x="1188.4" y="197" width="0.2" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1191.44" y="207.5" ></text>
</g>
<g >
<title>transformers/generation/utils.py(726):__expand_inputs_for_generation (183 us., 0.03%)</title><rect x="1189.6" y="229" width="0.4" height="15.0" fill="rgb(216,54,13)" rx="2" ry="2" />
<text  x="1192.65" y="239.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (226 us., 0.04%)</title><rect x="754.2" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="757.18" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,330 us., 0.37%)</title><rect x="1127.8" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1130.79" y="79.5" ></text>
</g>
<g >
<title>transformers/modeling_attn_mask_utils.py(77):_to_4d (460 us., 0.07%)</title><rect x="1180.0" y="133" width="0.9" height="15.0" fill="rgb(222,78,18)" rx="2" ry="2" />
<text  x="1182.99" y="143.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (88 us., 0.01%)</title><rect x="361.2" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="364.23" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (64 us., 0.01%)</title><rect x="583.0" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="586.04" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_15 (861 us., 0.14%)</title><rect x="1072.0" y="117" width="1.6" height="15.0" fill="rgb(247,193,46)" rx="2" ry="2" />
<text  x="1074.95" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,021 us., 0.97%)</title><rect x="244.7" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="247.75" y="63.5" ></text>
</g>
<g >
<title>ipykernel/kernelbase.py(539):_execute_request (623,012 us., 100.00%)</title><rect x="10.0" y="437" width="1180.0" height="15.0" fill="rgb(225,95,22)" rx="2" ry="2" />
<text  x="13.00" y="447.5" >ipykernel/kernelbase.py(539):_execute_request</text>
</g>
<g >
<title>transformers/activations.py(149):_forward (85 us., 0.01%)</title><rect x="204.5" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="207.51" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (103 us., 0.02%)</title><rect x="308.6" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="311.59" y="63.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (87 us., 0.01%)</title><rect x="538.3" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="541.32" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,360 us., 0.70%)</title><rect x="874.7" y="69" width="8.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="877.73" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_135 (1,262 us., 0.20%)</title><rect x="550.0" y="85" width="2.3" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="552.96" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_7 (12,443 us., 2.00%)</title><rect x="1018.9" y="117" width="23.6" height="15.0" fill="rgb(238,154,37)" rx="2" ry="2" />
<text  x="1021.89" y="127.5" >n..</text>
</g>
<g >
<title>IPython/core/interactiveshell.py(3553):_run_code (623,012 us., 100.00%)</title><rect x="10.0" y="293" width="1180.0" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="13.00" y="303.5" >IPython/core/interactiveshell.py(3553):_run_code</text>
</g>
<g >
<title>nn.Module:_Linear_54 (4,263 us., 0.68%)</title><rect x="1050.7" y="85" width="8.1" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="1053.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (1,040 us., 0.17%)</title><rect x="872.2" y="53" width="2.0" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="875.20" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (284 us., 0.05%)</title><rect x="364.0" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="366.99" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_3 (11,087 us., 1.78%)</title><rect x="786.3" y="117" width="21.0" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="789.29" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (160 us., 0.03%)</title><rect x="261.3" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="264.25" y="95.5" ></text>
</g>
<g >
<title>tornado/gen.py(250):_wrapper (623,012 us., 100.00%)</title><rect x="10.0" y="549" width="1180.0" height="15.0" fill="rgb(221,75,18)" rx="2" ry="2" />
<text  x="13.00" y="559.5" >tornado/gen.py(250):_wrapper</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,732 us., 0.28%)</title><rect x="214.1" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="217.08" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_78 (1,829 us., 0.29%)</title><rect x="162.3" y="85" width="3.4" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="165.25" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (257 us., 0.04%)</title><rect x="69.8" y="53" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="72.76" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (269 us., 0.04%)</title><rect x="153.8" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="156.84" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="782.4" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="785.35" y="63.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (2,229 us., 0.36%)</title><rect x="636.4" y="69" width="4.3" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="639.44" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="1122.1" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="1125.08" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (263 us., 0.04%)</title><rect x="124.0" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="126.99" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_max_of_Tensor_object_at_0x7b6685852b10&gt; (156 us., 0.03%)</title><rect x="10.9" y="213" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="13.90" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (165 us., 0.03%)</title><rect x="498.2" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="501.17" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_masked_fill__of_Tensor_object_at_0x7b6685840cc0&gt; (62 us., 0.01%)</title><rect x="1189.5" y="197" width="0.1" height="15.0" fill="rgb(219,66,15)" rx="2" ry="2" />
<text  x="1192.53" y="207.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,758 us., 0.76%)</title><rect x="444.3" y="53" width="9.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="447.34" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,618 us., 0.26%)</title><rect x="640.7" y="101" width="3.0" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="643.67" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,261 us., 0.68%)</title><rect x="341.7" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="344.74" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_2 (82 us., 0.01%)</title><rect x="782.4" y="85" width="0.1" height="15.0" fill="rgb(218,60,14)" rx="2" ry="2" />
<text  x="785.35" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_49 (2,334 us., 0.37%)</title><rect x="1023.1" y="85" width="4.5" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1026.15" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (816 us., 0.13%)</title><rect x="583.7" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="586.66" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (87 us., 0.01%)</title><rect x="538.3" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="541.32" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (166 us., 0.03%)</title><rect x="783.0" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="785.97" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_138 (3,439 us., 0.55%)</title><rect x="566.3" y="85" width="6.5" height="15.0" fill="rgb(223,86,20)" rx="2" ry="2" />
<text  x="569.31" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (260 us., 0.04%)</title><rect x="729.9" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="732.91" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,763 us., 0.76%)</title><rect x="719.7" y="69" width="9.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="722.71" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (68 us., 0.01%)</title><rect x="1177.7" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1180.67" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (92 us., 0.01%)</title><rect x="1014.9" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="1017.86" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_topk_of_type_object_at_0x7b66dec9e9c0&gt; (2,619 us., 0.42%)</title><rect x="1183.5" y="181" width="4.9" height="15.0" fill="rgb(231,120,28)" rx="2" ry="2" />
<text  x="1186.48" y="191.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_36 (998 us., 0.16%)</title><rect x="538.5" y="117" width="1.9" height="15.0" fill="rgb(227,104,25)" rx="2" ry="2" />
<text  x="541.48" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (832 us., 0.13%)</title><rect x="204.7" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="207.68" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (863 us., 0.14%)</title><rect x="644.6" y="85" width="1.7" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="647.65" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,275 us., 0.20%)</title><rect x="652.3" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="655.29" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (201 us., 0.03%)</title><rect x="966.3" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="969.31" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (162 us., 0.03%)</title><rect x="541.0" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="544.00" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (227 us., 0.04%)</title><rect x="457.6" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="460.61" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (355 us., 0.06%)</title><rect x="498.8" y="85" width="0.7" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="501.80" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (242 us., 0.04%)</title><rect x="430.2" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="433.25" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_52 (2,342 us., 0.38%)</title><rect x="1034.5" y="85" width="4.4" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="1037.48" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (92 us., 0.01%)</title><rect x="1014.9" y="53" width="0.1" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="1017.86" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,913 us., 1.91%)</title><rect x="559.6" y="101" width="22.6" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="562.61" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,258 us., 0.68%)</title><rect x="185.0" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="188.02" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,278 us., 0.21%)</title><rect x="694.6" y="69" width="2.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="697.64" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,820 us., 2.38%)</title><rect x="333.3" y="101" width="28.1" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="336.33" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (203 us., 0.03%)</title><rect x="428.1" y="69" width="0.3" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="431.05" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (126 us., 0.02%)</title><rect x="587.1" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="590.07" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_105 (2,319 us., 0.37%)</title><rect x="366.2" y="85" width="4.4" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="369.25" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,607 us., 1.70%)</title><rect x="104.8" y="101" width="20.1" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="107.82" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_59 (2,330 us., 0.37%)</title><rect x="1086.5" y="85" width="4.4" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="1089.53" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,727 us., 2.36%)</title><rect x="754.6" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="757.61" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,342 us., 0.38%)</title><rect x="1034.5" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1037.48" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_4 (14,713 us., 2.36%)</title><rect x="846.7" y="117" width="27.9" height="15.0" fill="rgb(208,13,3)" rx="2" ry="2" />
<text  x="849.71" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (161 us., 0.03%)</title><rect x="309.8" y="85" width="0.3" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="312.77" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (68 us., 0.01%)</title><rect x="1016.1" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1019.12" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,782 us., 0.29%)</title><rect x="1079.9" y="53" width="3.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1082.89" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,027 us., 0.97%)</title><rect x="297.2" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="300.17" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_26 (4,367 us., 0.70%)</title><rect x="815.6" y="85" width="8.3" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="818.60" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (5,506 us., 0.88%)</title><rect x="606.3" y="69" width="10.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="609.28" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,311 us., 0.69%)</title><rect x="385.5" y="69" width="8.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="388.51" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (203 us., 0.03%)</title><rect x="513.0" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="516.00" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_38 (786 us., 0.13%)</title><rect x="582.2" y="117" width="1.5" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="585.18" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,447 us., 0.55%)</title><rect x="522.8" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="525.78" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,443 us., 0.55%)</title><rect x="473.8" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="476.80" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,829 us., 0.29%)</title><rect x="162.3" y="53" width="3.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="165.25" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_35 (1,026 us., 0.16%)</title><rect x="497.5" y="117" width="2.0" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="500.53" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,166 us., 0.51%)</title><rect x="907.7" y="69" width="6.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="910.73" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (191 us., 0.03%)</title><rect x="1126.5" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1129.50" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (273 us., 0.04%)</title><rect x="1123.5" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1126.50" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,447 us., 0.55%)</title><rect x="522.8" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="525.78" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,285 us., 0.21%)</title><rect x="504.7" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="507.66" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (304 us., 0.05%)</title><rect x="749.6" y="85" width="0.6" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="752.60" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,721 us., 0.28%)</title><rect x="269.2" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="272.23" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,873 us., 0.30%)</title><rect x="466.6" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="469.60" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (130 us., 0.02%)</title><rect x="787.7" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="790.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (210 us., 0.03%)</title><rect x="927.7" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="930.69" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_40 (784 us., 0.13%)</title><rect x="686.4" y="117" width="1.5" height="15.0" fill="rgb(210,23,5)" rx="2" ry="2" />
<text  x="689.44" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (826 us., 0.13%)</title><rect x="363.0" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="365.96" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,722 us., 0.28%)</title><rect x="266.0" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="268.97" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (5,501 us., 0.88%)</title><rect x="78.9" y="53" width="10.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="81.95" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_110 (4,277 us., 0.69%)</title><rect x="393.7" y="85" width="8.1" height="15.0" fill="rgb(238,153,36)" rx="2" ry="2" />
<text  x="396.67" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_3 (30,330 us., 4.87%)</title><rect x="786.0" y="149" width="57.4" height="15.0" fill="rgb(230,115,27)" rx="2" ry="2" />
<text  x="788.96" y="159.5" >nn.Mod..</text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="1122.1" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1125.08" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (91 us., 0.01%)</title><rect x="835.3" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="838.29" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (240 us., 0.04%)</title><rect x="260.3" y="85" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="263.34" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_18 (22,473 us., 3.61%)</title><rect x="499.5" y="149" width="42.5" height="15.0" fill="rgb(231,120,28)" rx="2" ry="2" />
<text  x="502.47" y="159.5" >nn.M..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (112 us., 0.02%)</title><rect x="836.5" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="839.50" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (82 us., 0.01%)</title><rect x="256.1" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="259.15" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,026 us., 0.97%)</title><rect x="1110.7" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1113.67" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_42 (2,314 us., 0.37%)</title><rect x="967.4" y="85" width="4.4" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="970.39" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_13 (103 us., 0.02%)</title><rect x="308.6" y="85" width="0.2" height="15.0" fill="rgb(245,184,44)" rx="2" ry="2" />
<text  x="311.59" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_53 (4,270 us., 0.69%)</title><rect x="1042.6" y="85" width="8.1" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="1045.62" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (881 us., 0.14%)</title><rect x="1178.3" y="133" width="1.7" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1181.32" y="143.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (67 us., 0.01%)</title><rect x="643.1" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="646.07" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,026 us., 0.16%)</title><rect x="497.5" y="101" width="2.0" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="500.53" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (204 us., 0.03%)</title><rect x="1090.9" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="1093.94" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,704 us., 0.27%)</title><rect x="1135.5" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1138.51" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (206 us., 0.03%)</title><rect x="556.1" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="559.14" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (954 us., 0.15%)</title><rect x="257.9" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="260.85" y="111.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (92 us., 0.01%)</title><rect x="1070.2" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1073.18" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (276 us., 0.04%)</title><rect x="731.8" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="734.78" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (67 us., 0.01%)</title><rect x="963.2" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="966.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,029 us., 0.97%)</title><rect x="349.8" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="352.81" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (178 us., 0.03%)</title><rect x="1180.4" y="101" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1183.40" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_31 (3,617 us., 0.58%)</title><rect x="861.4" y="85" width="6.9" height="15.0" fill="rgb(235,140,33)" rx="2" ry="2" />
<text  x="864.45" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (64 us., 0.01%)</title><rect x="205.6" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="208.60" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (62 us., 0.01%)</title><rect x="257.1" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="260.11" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (224 us., 0.04%)</title><rect x="70.2" y="69" width="0.5" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="73.25" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,729 us., 4.45%)</title><rect x="1125.8" y="133" width="52.5" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="1128.80" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (273 us., 0.04%)</title><rect x="785.4" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="788.45" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,315 us., 0.21%)</title><rect x="603.2" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="606.22" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,280 us., 0.69%)</title><rect x="70.8" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="73.84" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,260 us., 0.68%)</title><rect x="1155.1" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1158.15" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_3 (1,634 us., 0.26%)</title><rect x="643.7" y="117" width="3.1" height="15.0" fill="rgb(226,99,23)" rx="2" ry="2" />
<text  x="646.73" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_45 (2,342 us., 0.38%)</title><rect x="979.3" y="85" width="4.5" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="982.31" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (196 us., 0.03%)</title><rect x="1019.3" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="1022.26" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,014 us., 0.97%)</title><rect x="891.0" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="894.04" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (70 us., 0.01%)</title><rect x="783.5" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="786.49" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,742 us., 0.76%)</title><rect x="677.3" y="53" width="9.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="680.30" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (118 us., 0.02%)</title><rect x="1075.3" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1078.26" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="1175.8" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1178.81" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,796 us., 2.37%)</title><rect x="874.6" y="101" width="28.0" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="877.58" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (266 us., 0.04%)</title><rect x="964.3" y="85" width="0.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="967.33" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,254 us., 0.68%)</title><rect x="236.7" y="53" width="8.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="239.69" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (168 us., 0.03%)</title><rect x="411.9" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="414.89" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (268 us., 0.04%)</title><rect x="497.0" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="500.02" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (32,945 us., 5.29%)</title><rect x="843.4" y="133" width="62.4" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="846.41" y="143.5" >transf..</text>
</g>
<g >
<title>nn.Module:_Linear_151 (3,424 us., 0.55%)</title><rect x="706.7" y="85" width="6.5" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="709.69" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_66 (2,371 us., 0.38%)</title><rect x="1138.7" y="85" width="4.5" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="1141.73" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,270 us., 0.69%)</title><rect x="1042.6" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1045.62" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,449 us., 0.55%)</title><rect x="559.8" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="562.78" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_16 (80 us., 0.01%)</title><rect x="453.3" y="85" width="0.2" height="15.0" fill="rgb(225,95,22)" rx="2" ry="2" />
<text  x="456.35" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,731 us., 0.28%)</title><rect x="58.1" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="61.12" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (124 us., 0.02%)</title><rect x="847.9" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="850.91" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_11 (27,387 us., 4.40%)</title><rect x="155.9" y="149" width="51.9" height="15.0" fill="rgb(226,98,23)" rx="2" ry="2" />
<text  x="158.93" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (80 us., 0.01%)</title><rect x="453.3" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="456.35" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (116 us., 0.02%)</title><rect x="500.9" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="503.91" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,438 us., 0.39%)</title><rect x="377.2" y="69" width="4.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="380.15" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (174 us., 0.03%)</title><rect x="641.1" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="644.14" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,261 us., 0.68%)</title><rect x="341.7" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="344.74" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,334 us., 0.37%)</title><rect x="117.1" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="120.14" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,917 us., 0.31%)</title><rect x="795.7" y="53" width="3.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="798.68" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,254 us., 0.36%)</title><rect x="975.0" y="53" width="4.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="978.05" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (70 us., 0.01%)</title><rect x="539.7" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="542.74" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (225 us., 0.04%)</title><rect x="384.9" y="85" width="0.5" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="387.93" y="95.5" ></text>
</g>
<g >
<title>torch/_tensor.py(33):_wrapped (67 us., 0.01%)</title><rect x="1180.7" y="101" width="0.2" height="15.0" fill="rgb(223,84,20)" rx="2" ry="2" />
<text  x="1183.74" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,329 us., 0.37%)</title><rect x="1075.5" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1078.48" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,445 us., 0.55%)</title><rect x="480.3" y="53" width="6.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="483.33" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_147 (1,854 us., 0.30%)</title><rect x="691.1" y="85" width="3.5" height="15.0" fill="rgb(223,86,20)" rx="2" ry="2" />
<text  x="694.13" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (102 us., 0.02%)</title><rect x="455.7" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="458.74" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (214 us., 0.03%)</title><rect x="733.8" y="85" width="0.4" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="736.84" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (103 us., 0.02%)</title><rect x="498.5" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="501.48" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,059 us., 0.17%)</title><rect x="308.8" y="101" width="2.0" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="311.78" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_21 (82 us., 0.01%)</title><rect x="728.7" y="85" width="0.2" height="15.0" fill="rgb(251,214,51)" rx="2" ry="2" />
<text  x="731.73" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="155.3" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="158.30" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (256 us., 0.04%)</title><rect x="787.2" y="85" width="0.5" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="790.23" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (122 us., 0.02%)</title><rect x="458.0" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="461.04" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (70 us., 0.01%)</title><rect x="413.8" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="416.79" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (62 us., 0.01%)</title><rect x="207.0" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="210.04" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (486 us., 0.08%)</title><rect x="1041.1" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="1044.08" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,728 us., 2.36%)</title><rect x="176.8" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="179.78" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (71 us., 0.01%)</title><rect x="688.8" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="691.78" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,045 us., 0.97%)</title><rect x="770.9" y="53" width="11.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="773.90" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_25 (954 us., 0.15%)</title><rect x="257.9" y="117" width="1.8" height="15.0" fill="rgb(240,164,39)" rx="2" ry="2" />
<text  x="260.85" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (123 us., 0.02%)</title><rect x="106.0" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="108.98" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,323 us., 0.37%)</title><rect x="322.4" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="325.40" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,436 us., 0.55%)</title><rect x="670.8" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="673.79" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,443 us., 0.55%)</title><rect x="473.8" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="476.80" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,264 us., 0.20%)</title><rect x="464.2" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="467.20" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (175 us., 0.03%)</title><rect x="361.9" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="364.87" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_8 (10,757 us., 1.73%)</title><rect x="1074.0" y="117" width="20.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1077.00" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (376 us., 0.06%)</title><rect x="312.2" y="85" width="0.7" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="315.22" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_9 (86 us., 0.01%)</title><rect x="1174.6" y="85" width="0.2" height="15.0" fill="rgb(222,82,19)" rx="2" ry="2" />
<text  x="1177.64" y="95.5" ></text>
</g>
<g >
<title>tornado/ioloop.py(738):__run_callback (623,012 us., 100.00%)</title><rect x="10.0" y="613" width="1180.0" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="13.00" y="623.5" >tornado/ioloop.py(738):__run_callback</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_6 (1,105 us., 0.18%)</title><rect x="835.5" y="117" width="2.1" height="15.0" fill="rgb(207,10,2)" rx="2" ry="2" />
<text  x="838.47" y="127.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (204 us., 0.03%)</title><rect x="1090.9" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1093.94" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,817 us., 1.90%)</title><rect x="516.1" y="101" width="22.4" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="519.10" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,424 us., 0.55%)</title><rect x="706.7" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="709.69" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (288 us., 0.05%)</title><rect x="905.3" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="908.26" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (84 us., 0.01%)</title><rect x="960.4" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="963.36" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,268 us., 0.69%)</title><rect x="125.1" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="128.07" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,263 us., 0.68%)</title><rect x="762.8" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="765.83" y="63.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (201 us., 0.03%)</title><rect x="1143.2" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1146.22" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_79 (1,812 us., 0.29%)</title><rect x="165.7" y="85" width="3.4" height="15.0" fill="rgb(207,13,3)" rx="2" ry="2" />
<text  x="168.72" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,550 us., 1.69%)</title><rect x="313.3" y="101" width="20.0" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="316.34" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (2,084 us., 0.33%)</title><rect x="928.1" y="85" width="3.9" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="931.09" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,433 us., 0.23%)</title><rect x="1143.6" y="85" width="2.7" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="1146.60" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (586 us., 0.09%)</title><rect x="705.0" y="69" width="1.1" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="708.00" y="79.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (92 us., 0.01%)</title><rect x="902.4" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="905.43" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,722 us., 0.28%)</title><rect x="266.0" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="268.97" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (950 us., 0.15%)</title><rect x="101.1" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="104.10" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (11,605 us., 1.86%)</title><rect x="732.6" y="101" width="22.0" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="735.63" y="111.5" >t..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (464 us., 0.07%)</title><rect x="753.3" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="756.31" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,271 us., 0.69%)</title><rect x="176.9" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="179.94" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,758 us., 0.76%)</title><rect x="444.3" y="69" width="9.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="447.34" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_19 (22,793 us., 3.66%)</title><rect x="542.0" y="149" width="43.2" height="15.0" fill="rgb(224,91,21)" rx="2" ry="2" />
<text  x="545.04" y="159.5" >nn.M..</text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (228 us., 0.04%)</title><rect x="260.8" y="85" width="0.5" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="263.82" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (436 us., 0.07%)</title><rect x="558.4" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="561.37" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="363.9" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="366.87" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,878 us., 2.39%)</title><rect x="807.3" y="101" width="28.2" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="810.29" y="111.5" >t..</text>
</g>
<g >
<title>nn.Module:_Linear_148 (1,278 us., 0.21%)</title><rect x="694.6" y="85" width="2.5" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="697.64" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,744 us., 0.28%)</title><rect x="1132.2" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1135.20" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_28 (826 us., 0.13%)</title><rect x="361.4" y="117" width="1.6" height="15.0" fill="rgb(221,75,17)" rx="2" ry="2" />
<text  x="364.39" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,469 us., 0.24%)</title><rect x="382.1" y="85" width="2.8" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="385.15" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,029 us., 0.97%)</title><rect x="349.8" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="352.81" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (2,115 us., 0.34%)</title><rect x="750.2" y="85" width="4.0" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="753.18" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (224 us., 0.04%)</title><rect x="314.1" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="317.09" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,366 us., 0.22%)</title><rect x="225.4" y="85" width="2.6" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="228.42" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_65 (1,704 us., 0.27%)</title><rect x="1135.5" y="85" width="3.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1138.51" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_embedding_of_type_object_at_0x7b66dec9e9c0&gt; (125 us., 0.02%)</title><rect x="46.7" y="101" width="0.2" height="15.0" fill="rgb(223,87,20)" rx="2" ry="2" />
<text  x="49.71" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (939 us., 0.15%)</title><rect x="1174.8" y="101" width="1.8" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1177.80" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,323 us., 0.37%)</title><rect x="106.2" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="109.21" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,314 us., 0.37%)</title><rect x="967.4" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="970.39" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (292 us., 0.05%)</title><rect x="103.9" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="106.95" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,335 us., 0.37%)</title><rect x="799.3" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="802.31" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,026 us., 0.97%)</title><rect x="1110.7" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1113.67" y="79.5" ></text>
</g>
<g >
<title>IPython/core/async_helpers.py(78):__pseudo_sync_runner (623,012 us., 100.00%)</title><rect x="10.0" y="341" width="1180.0" height="15.0" fill="rgb(213,37,9)" rx="2" ry="2" />
<text  x="13.00" y="351.5" >IPython/core/async_helpers.py(78):__pseudo_sync_runner</text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="541.4" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="544.43" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (257 us., 0.04%)</title><rect x="806.4" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="809.36" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_4 (4,280 us., 0.69%)</title><rect x="70.8" y="85" width="8.1" height="15.0" fill="rgb(245,186,44)" rx="2" ry="2" />
<text  x="73.84" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (16,162 us., 2.59%)</title><rect x="16.1" y="149" width="30.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="19.10" y="159.5" >&lt;b..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,330 us., 0.37%)</title><rect x="261.6" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="264.56" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (88 us., 0.01%)</title><rect x="361.2" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="364.23" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_20 (22,493 us., 3.61%)</title><rect x="646.8" y="149" width="42.6" height="15.0" fill="rgb(226,98,23)" rx="2" ry="2" />
<text  x="649.83" y="159.5" >nn.M..</text>
</g>
<g >
<title>nn.Module:_Linear_12 (4,368 us., 0.70%)</title><rect x="616.7" y="85" width="8.3" height="15.0" fill="rgb(241,169,40)" rx="2" ry="2" />
<text  x="619.71" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="412.3" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="415.35" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,339 us., 0.38%)</title><rect x="788.0" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="790.96" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_11 (10,843 us., 1.74%)</title><rect x="156.2" y="117" width="20.6" height="15.0" fill="rgb(210,26,6)" rx="2" ry="2" />
<text  x="159.24" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_2 (28,331 us., 4.55%)</title><rect x="732.3" y="149" width="53.7" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="735.30" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="728.7" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="731.73" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (986 us., 0.16%)</title><rect x="65.8" y="85" width="1.9" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="68.84" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,384 us., 0.38%)</title><rect x="923.2" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="926.18" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,458 us., 0.23%)</title><rect x="703.3" y="85" width="2.8" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="706.35" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_12 (27,383 us., 4.40%)</title><rect x="207.8" y="149" width="51.9" height="15.0" fill="rgb(220,69,16)" rx="2" ry="2" />
<text  x="210.80" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,342 us., 0.38%)</title><rect x="272.5" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="275.49" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (426 us., 0.07%)</title><rect x="514.9" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="517.87" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,869 us., 0.30%)</title><rect x="424.5" y="69" width="3.6" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="427.51" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_12 (10,710 us., 1.72%)</title><rect x="208.1" y="117" width="20.3" height="15.0" fill="rgb(254,227,54)" rx="2" ry="2" />
<text  x="211.13" y="127.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="152.7" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="155.65" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_27 (1,133 us., 0.18%)</title><rect x="310.8" y="117" width="2.1" height="15.0" fill="rgb(227,104,25)" rx="2" ry="2" />
<text  x="313.79" y="127.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (494 us., 0.08%)</title><rect x="985.8" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="988.75" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,367 us., 0.70%)</title><rect x="815.6" y="69" width="8.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="818.60" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (218 us., 0.03%)</title><rect x="559.2" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="562.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (69 us., 0.01%)</title><rect x="729.8" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="732.77" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (214 us., 0.03%)</title><rect x="874.2" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="877.17" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (128 us., 0.02%)</title><rect x="967.1" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="970.15" y="95.5" ></text>
</g>
<g >
<title>runpy.py(196):__run_module_as_main (623,012 us., 100.00%)</title><rect x="10.0" y="773" width="1180.0" height="15.0" fill="rgb(238,153,36)" rx="2" ry="2" />
<text  x="13.00" y="783.5" >runpy.py(196):__run_module_as_main</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (231 us., 0.04%)</title><rect x="806.9" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="809.85" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (85 us., 0.01%)</title><rect x="411.2" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="414.22" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (73 us., 0.01%)</title><rect x="1071.2" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1074.18" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,828 us., 0.29%)</title><rect x="1027.6" y="53" width="3.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1030.57" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_143 (1,969 us., 0.32%)</title><rect x="657.1" y="85" width="3.7" height="15.0" fill="rgb(249,205,49)" rx="2" ry="2" />
<text  x="660.08" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (224 us., 0.04%)</title><rect x="365.6" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="368.58" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_33 (805 us., 0.13%)</title><rect x="455.0" y="117" width="1.5" height="15.0" fill="rgb(247,193,46)" rx="2" ry="2" />
<text  x="458.02" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (68 us., 0.01%)</title><rect x="1179.2" y="117" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1182.25" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (318 us., 0.05%)</title><rect x="310.2" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="313.19" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,447 us., 0.55%)</title><rect x="713.2" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="716.18" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,033 us., 0.97%)</title><rect x="141.2" y="53" width="11.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="144.23" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (241 us., 0.04%)</title><rect x="1042.0" y="69" width="0.5" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="1045.00" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,326 us., 0.37%)</title><rect x="220.6" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="223.64" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,332 us., 0.37%)</title><rect x="169.1" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="172.15" y="63.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (295 us., 0.05%)</title><rect x="470.1" y="85" width="0.6" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="473.15" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="1017.9" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1020.94" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="782.4" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="785.35" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (455 us., 0.07%)</title><rect x="227.1" y="69" width="0.9" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="230.14" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_14 (2,322 us., 0.37%)</title><rect x="734.2" y="85" width="4.4" height="15.0" fill="rgb(229,110,26)" rx="2" ry="2" />
<text  x="737.24" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,711 us., 0.27%)</title><rect x="373.9" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="376.91" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,726 us., 2.36%)</title><rect x="228.4" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="231.41" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,266 us., 0.68%)</title><rect x="932.8" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="935.81" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (786 us., 0.13%)</title><rect x="582.2" y="101" width="1.5" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="585.18" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="903.4" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="906.41" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (318 us., 0.05%)</title><rect x="280.0" y="85" width="0.6" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="282.97" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (13,992 us., 2.25%)</title><rect x="906.1" y="101" width="26.5" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="909.13" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (72 us., 0.01%)</title><rect x="539.6" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="542.60" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (8,609 us., 1.38%)</title><rect x="499.8" y="101" width="16.3" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="502.79" y="111.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (27,383 us., 4.40%)</title><rect x="207.8" y="133" width="51.9" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="210.80" y="143.5" >trans..</text>
</g>
<g >
<title>nn.Module:_Linear_132 (4,756 us., 0.76%)</title><rect x="529.3" y="85" width="9.0" height="15.0" fill="rgb(212,34,8)" rx="2" ry="2" />
<text  x="532.31" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,330 us., 0.37%)</title><rect x="1086.5" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1089.53" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_43 (1,006 us., 0.16%)</title><rect x="730.4" y="117" width="1.9" height="15.0" fill="rgb(240,164,39)" rx="2" ry="2" />
<text  x="733.40" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_19 (11,913 us., 1.91%)</title><rect x="559.6" y="117" width="22.6" height="15.0" fill="rgb(240,165,39)" rx="2" ry="2" />
<text  x="562.61" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (215 us., 0.03%)</title><rect x="176.4" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="179.37" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (66 us., 0.01%)</title><rect x="836.7" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="839.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (116 us., 0.02%)</title><rect x="416.0" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="418.98" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,271 us., 0.69%)</title><rect x="176.9" y="53" width="8.1" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="179.94" y="63.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (205 us., 0.03%)</title><rect x="602.8" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="605.83" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_113 (1,273 us., 0.20%)</title><rect x="419.7" y="85" width="2.4" height="15.0" fill="rgb(218,64,15)" rx="2" ry="2" />
<text  x="422.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,730 us., 0.28%)</title><rect x="599.6" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="602.55" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,337 us., 0.38%)</title><rect x="587.3" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="590.31" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,031 us., 0.97%)</title><rect x="823.9" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="826.87" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,812 us., 0.29%)</title><rect x="165.7" y="53" width="3.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="168.72" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (123 us., 0.02%)</title><rect x="1127.6" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1130.56" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_5 (14,722 us., 2.36%)</title><rect x="932.6" y="117" width="27.9" height="15.0" fill="rgb(233,130,31)" rx="2" ry="2" />
<text  x="935.63" y="127.5" >n..</text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_24 (818 us., 0.13%)</title><rect x="256.3" y="117" width="1.6" height="15.0" fill="rgb(247,193,46)" rx="2" ry="2" />
<text  x="259.30" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (379 us., 0.06%)</title><rect x="836.8" y="85" width="0.8" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="839.84" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (821 us., 0.13%)</title><rect x="413.0" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="416.00" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,003 us., 0.32%)</title><rect x="552.3" y="69" width="3.8" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="555.35" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,863 us., 0.30%)</title><rect x="501.1" y="53" width="3.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="504.13" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,859 us., 0.30%)</title><rect x="416.2" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="419.20" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (161 us., 0.03%)</title><rect x="209.4" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="212.37" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_18 (8,609 us., 1.38%)</title><rect x="499.8" y="117" width="16.3" height="15.0" fill="rgb(215,48,11)" rx="2" ry="2" />
<text  x="502.79" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,252 us., 0.68%)</title><rect x="754.8" y="69" width="8.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="757.77" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (219 us., 0.04%)</title><rect x="430.7" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="433.70" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,731 us., 2.36%)</title><rect x="124.9" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="127.91" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (275 us., 0.04%)</title><rect x="1177.8" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1180.80" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_98 (2,323 us., 0.37%)</title><rect x="322.4" y="85" width="4.4" height="15.0" fill="rgb(251,213,51)" rx="2" ry="2" />
<text  x="325.40" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_119 (1,857 us., 0.30%)</title><rect x="458.3" y="85" width="3.5" height="15.0" fill="rgb(230,115,27)" rx="2" ry="2" />
<text  x="461.28" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,739 us., 0.28%)</title><rect x="919.9" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="922.88" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (429 us., 0.07%)</title><rect x="429.9" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="432.89" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_19 (4,263 us., 0.68%)</title><rect x="762.8" y="85" width="8.1" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="765.83" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,045 us., 0.97%)</title><rect x="770.9" y="69" width="11.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="773.90" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,763 us., 0.76%)</title><rect x="719.7" y="53" width="9.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="722.71" y="63.5" ></text>
</g>
<g >
<title>torch/_tensor.py(831):___rsub__ (67 us., 0.01%)</title><rect x="1180.7" y="85" width="0.2" height="15.0" fill="rgb(228,109,26)" rx="2" ry="2" />
<text  x="1183.74" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_34 (803 us., 0.13%)</title><rect x="496.0" y="117" width="1.5" height="15.0" fill="rgb(240,164,39)" rx="2" ry="2" />
<text  x="499.01" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (283 us., 0.05%)</title><rect x="412.5" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="415.47" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (234 us., 0.04%)</title><rect x="157.0" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="159.99" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (226 us., 0.04%)</title><rect x="754.2" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="757.18" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_129 (1,861 us., 0.30%)</title><rect x="509.5" y="85" width="3.5" height="15.0" fill="rgb(223,86,20)" rx="2" ry="2" />
<text  x="512.48" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_14 (27,237 us., 4.37%)</title><rect x="312.9" y="149" width="51.6" height="15.0" fill="rgb(207,9,2)" rx="2" ry="2" />
<text  x="315.94" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,439 us., 0.55%)</title><rect x="437.8" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="440.82" y="63.5" ></text>
</g>
<g >
<title>torch/_tensor.py(831):___rsub__ (60 us., 0.01%)</title><rect x="1180.9" y="197" width="0.1" height="15.0" fill="rgb(228,109,26)" rx="2" ry="2" />
<text  x="1183.86" y="207.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,637 us., 3.63%)</title><rect x="689.4" y="133" width="42.9" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="692.43" y="143.5" >tran..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,742 us., 0.76%)</title><rect x="677.3" y="69" width="9.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="680.30" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (68 us., 0.01%)</title><rect x="584.4" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="587.44" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_repeat_interleave_of_Tensor_object_at_0x7b6685842b10&gt; (85 us., 0.01%)</title><rect x="1189.8" y="197" width="0.2" height="15.0" fill="rgb(236,143,34)" rx="2" ry="2" />
<text  x="1192.84" y="207.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,052 us., 0.97%)</title><rect x="625.0" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="627.98" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_16 (22,170 us., 3.56%)</title><rect x="414.6" y="149" width="41.9" height="15.0" fill="rgb(244,180,43)" rx="2" ry="2" />
<text  x="417.56" y="159.5" >nn...</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,754 us., 0.76%)</title><rect x="486.9" y="53" width="9.0" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="489.85" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_55 (6,014 us., 0.97%)</title><rect x="1058.8" y="85" width="11.4" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="1061.79" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="728.7" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="731.73" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (275 us., 0.04%)</title><rect x="207.3" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="210.28" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,812 us., 0.29%)</title><rect x="165.7" y="69" width="3.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="168.72" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (2,299 us., 0.37%)</title><rect x="838.1" y="85" width="4.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="841.09" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="495.9" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="498.86" y="47.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,274 us., 0.20%)</title><rect x="547.5" y="53" width="2.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="550.54" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_repeat_interleave_of_Tensor_object_at_0x7b6685842b10&gt; (98 us., 0.02%)</title><rect x="1189.6" y="213" width="0.2" height="15.0" fill="rgb(236,143,34)" rx="2" ry="2" />
<text  x="1192.65" y="223.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (218 us., 0.03%)</title><rect x="1094.0" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="1096.96" y="95.5" ></text>
</g>
<g >
<title>transformers/generation/utils.py(1350):_generate (623,010 us., 100.00%)</title><rect x="10.0" y="245" width="1180.0" height="15.0" fill="rgb(210,27,6)" rx="2" ry="2" />
<text  x="13.00" y="255.5" >transformers/generation/utils.py(1350):_generate</text>
</g>
<g >
<title>nn.Module:_Linear_1 (1,728 us., 0.28%)</title><rect x="54.8" y="85" width="3.3" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="57.85" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (85 us., 0.01%)</title><rect x="411.2" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="414.22" y="47.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,447 us., 0.55%)</title><rect x="713.2" y="69" width="6.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="716.18" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_76 (6,033 us., 0.97%)</title><rect x="141.2" y="85" width="11.5" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="144.23" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,371 us., 0.38%)</title><rect x="591.7" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="594.73" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (65 us., 0.01%)</title><rect x="1175.9" y="85" width="0.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1178.94" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (164 us., 0.03%)</title><rect x="1123.2" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1126.19" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (220 us., 0.04%)</title><rect x="105.6" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="108.56" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,330 us., 0.37%)</title><rect x="1127.8" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1130.79" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,352 us., 0.70%)</title><rect x="333.5" y="53" width="8.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="336.50" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (167 us., 0.03%)</title><rect x="582.6" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="585.60" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="1071.3" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1074.32" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (164 us., 0.03%)</title><rect x="455.4" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="458.43" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (184 us., 0.03%)</title><rect x="647.7" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="650.69" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_106 (1,728 us., 0.28%)</title><rect x="370.6" y="85" width="3.3" height="15.0" fill="rgb(206,4,1)" rx="2" ry="2" />
<text  x="373.64" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (183 us., 0.03%)</title><rect x="1122.7" y="85" width="0.4" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1125.72" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,334 us., 0.37%)</title><rect x="1023.1" y="53" width="4.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1026.15" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_15 (1,728 us., 0.28%)</title><rect x="738.6" y="85" width="3.3" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="741.64" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,732 us., 0.28%)</title><rect x="326.8" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="329.80" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (229 us., 0.04%)</title><rect x="332.9" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="335.89" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (6,014 us., 0.97%)</title><rect x="1058.8" y="53" width="11.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1061.79" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_19 (85 us., 0.01%)</title><rect x="582.0" y="85" width="0.2" height="15.0" fill="rgb(206,6,1)" rx="2" ry="2" />
<text  x="585.01" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_10 (2,337 us., 0.38%)</title><rect x="587.3" y="85" width="4.4" height="15.0" fill="rgb(254,229,54)" rx="2" ry="2" />
<text  x="590.31" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_72 (1,723 us., 0.28%)</title><rect x="113.9" y="85" width="3.2" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="116.88" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_13 (14,896 us., 2.39%)</title><rect x="280.6" y="117" width="28.2" height="15.0" fill="rgb(229,113,27)" rx="2" ry="2" />
<text  x="283.57" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (208 us., 0.03%)</title><rect x="703.0" y="69" width="0.3" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="705.95" y="79.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (206 us., 0.03%)</title><rect x="276.9" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="279.93" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (103 us., 0.02%)</title><rect x="308.6" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="311.59" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (282 us., 0.05%)</title><rect x="842.9" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="845.87" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (357 us., 0.06%)</title><rect x="543.1" y="85" width="0.7" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="546.11" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,729 us., 0.28%)</title><rect x="971.8" y="69" width="3.2" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="974.77" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,258 us., 0.68%)</title><rect x="185.0" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="188.02" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_28 (2,329 us., 0.37%)</title><rect x="848.1" y="85" width="4.5" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="851.15" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,263 us., 0.68%)</title><rect x="762.8" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="765.83" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (251 us., 0.04%)</title><rect x="472.8" y="53" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="475.75" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (224 us., 0.04%)</title><rect x="70.2" y="85" width="0.5" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="73.25" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (304 us., 0.05%)</title><rect x="749.6" y="69" width="0.6" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="752.60" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_36 (3,249 us., 0.52%)</title><rect x="913.7" y="85" width="6.2" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="916.73" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_88 (4,277 us., 0.69%)</title><rect x="228.6" y="85" width="8.1" height="15.0" fill="rgb(207,13,3)" rx="2" ry="2" />
<text  x="231.59" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (173 us., 0.03%)</title><rect x="363.4" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="366.41" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_14 (88 us., 0.01%)</title><rect x="361.2" y="85" width="0.2" height="15.0" fill="rgb(238,154,37)" rx="2" ry="2" />
<text  x="364.23" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_SiLUActivation_18 (87 us., 0.01%)</title><rect x="538.3" y="85" width="0.2" height="15.0" fill="rgb(212,35,8)" rx="2" ry="2" />
<text  x="541.32" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (67 us., 0.01%)</title><rect x="413.9" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="416.92" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (18,237 us., 2.93%)</title><rect x="606.1" y="101" width="34.6" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="609.13" y="111.5" >tr..</text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (66 us., 0.01%)</title><rect x="785.3" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="788.32" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_34 (6,014 us., 0.97%)</title><rect x="891.0" y="85" width="11.4" height="15.0" fill="rgb(216,51,12)" rx="2" ry="2" />
<text  x="894.04" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (181 us., 0.03%)</title><rect x="256.8" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="259.77" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (249 us., 0.04%)</title><rect x="48.1" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="51.06" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (72 us., 0.01%)</title><rect x="101.9" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="104.93" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_7 (14,725 us., 2.36%)</title><rect x="1042.5" y="117" width="27.9" height="15.0" fill="rgb(220,70,16)" rx="2" ry="2" />
<text  x="1045.46" y="127.5" >n..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,342 us., 0.38%)</title><rect x="1034.5" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1037.48" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (271 us., 0.04%)</title><rect x="1018.1" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1021.06" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (11,775 us., 1.89%)</title><rect x="664.1" y="101" width="22.3" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="667.13" y="111.5" >t..</text>
</g>
<g >
<title>transformers/generation/logits_process.py(447):___call__ (2,871 us., 0.46%)</title><rect x="1183.0" y="197" width="5.4" height="15.0" fill="rgb(216,53,12)" rx="2" ry="2" />
<text  x="1186.00" y="207.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_33 (4,248 us., 0.68%)</title><rect x="883.0" y="85" width="8.0" height="15.0" fill="rgb(222,80,19)" rx="2" ry="2" />
<text  x="885.99" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_19 (919 us., 0.15%)</title><rect x="1176.6" y="117" width="1.7" height="15.0" fill="rgb(221,75,17)" rx="2" ry="2" />
<text  x="1179.58" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (290 us., 0.05%)</title><rect x="1073.0" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1076.04" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="257.2" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="260.23" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,858 us., 0.30%)</title><rect x="699.4" y="53" width="3.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="702.43" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (164 us., 0.03%)</title><rect x="688.4" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="691.36" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (9,113 us., 1.46%)</title><rect x="542.4" y="101" width="17.2" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="545.35" y="111.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,334 us., 0.37%)</title><rect x="745.2" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="748.18" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(836):_forward (598,806 us., 96.11%)</title><rect x="46.7" y="165" width="1134.2" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="49.71" y="175.5" >transformers/models/llama/modeling_llama.py(836):_forward</text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (198 us., 0.03%)</title><rect x="381.8" y="69" width="0.3" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="384.77" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_15 (13,740 us., 2.21%)</title><rect x="385.4" y="117" width="26.0" height="15.0" fill="rgb(216,54,12)" rx="2" ry="2" />
<text  x="388.35" y="127.5" >n..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,969 us., 0.32%)</title><rect x="657.1" y="69" width="3.7" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="660.08" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,133 us., 0.18%)</title><rect x="310.8" y="101" width="2.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="313.79" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (82 us., 0.01%)</title><rect x="1122.1" y="37" width="0.1" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="1125.08" y="47.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,052 us., 0.97%)</title><rect x="625.0" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="627.98" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_29 (826 us., 0.13%)</title><rect x="363.0" y="117" width="1.5" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="365.96" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (64 us., 0.01%)</title><rect x="454.3" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="457.27" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (3,439 us., 0.55%)</title><rect x="566.3" y="53" width="6.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="569.31" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (924 us., 0.15%)</title><rect x="963.9" y="101" width="1.7" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="966.86" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_matmul_of_type_object_at_0x7b66dec9e9c0&gt; (199 us., 0.03%)</title><rect x="500.5" y="85" width="0.4" height="15.0" fill="rgb(224,90,21)" rx="2" ry="2" />
<text  x="503.54" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (220 us., 0.04%)</title><rect x="124.5" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="127.49" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_67 (4,254 us., 0.68%)</title><rect x="1147.1" y="85" width="8.0" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1150.09" y="95.5" ></text>
</g>
<g >
<title>all (623,012 us., 100%)</title><rect x="10.0" y="789" width="1180.0" height="15.0" fill="rgb(213,39,9)" rx="2" ry="2" />
<text  x="13.00" y="799.5" ></text>
</g>
<g >
<title>&lt;built-in_function_silu&gt; (85 us., 0.01%)</title><rect x="582.0" y="37" width="0.2" height="15.0" fill="rgb(209,20,5)" rx="2" ry="2" />
<text  x="585.01" y="47.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(263):_repeat_kv (219 us., 0.04%)</title><rect x="986.7" y="85" width="0.4" height="15.0" fill="rgb(214,44,10)" rx="2" ry="2" />
<text  x="989.69" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_136 (2,003 us., 0.32%)</title><rect x="552.3" y="85" width="3.8" height="15.0" fill="rgb(236,145,34)" rx="2" ry="2" />
<text  x="555.35" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (82 us., 0.01%)</title><rect x="495.9" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="498.86" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,341 us., 0.22%)</title><rect x="122.0" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="124.95" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,306 us., 0.69%)</title><rect x="289.0" y="53" width="8.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="292.02" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,334 us., 0.37%)</title><rect x="117.1" y="69" width="4.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="120.14" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_masked_fill_of_Tensor_object_at_0x7b66858408b0&gt; (154 us., 0.02%)</title><rect x="1180.1" y="101" width="0.3" height="15.0" fill="rgb(217,57,13)" rx="2" ry="2" />
<text  x="1183.11" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (71 us., 0.01%)</title><rect x="496.9" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="499.89" y="95.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (88 us., 0.01%)</title><rect x="361.2" y="69" width="0.2" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="364.23" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (12,443 us., 2.00%)</title><rect x="1018.9" y="101" width="23.6" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="1021.89" y="111.5" >t..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,736 us., 0.28%)</title><rect x="792.4" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="795.39" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (76 us., 0.01%)</title><rect x="103.7" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="106.68" y="95.5" ></text>
</g>
<g >
<title>tornado/gen.py(234):_wrapper (623,012 us., 100.00%)</title><rect x="10.0" y="421" width="1180.0" height="15.0" fill="rgb(208,16,3)" rx="2" ry="2" />
<text  x="13.00" y="431.5" >tornado/gen.py(234):_wrapper</text>
</g>
<g >
<title>traitlets/config/application.py(992):_launch_instance (623,012 us., 100.00%)</title><rect x="10.0" y="725" width="1180.0" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="13.00" y="735.5" >traitlets/config/application.py(992):_launch_instance</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,340 us., 0.22%)</title><rect x="67.7" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="70.71" y="95.5" ></text>
</g>
<g >
<title>transformers/modeling_attn_mask_utils.py(119):__make_causal_mask (53 us., 0.01%)</title><rect x="1180.0" y="117" width="0.1" height="15.0" fill="rgb(223,86,20)" rx="2" ry="2" />
<text  x="1183.01" y="127.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (1,068 us., 0.17%)</title><rect x="1181.0" y="213" width="2.0" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="1183.98" y="223.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (118 us., 0.02%)</title><rect x="648.6" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="651.56" y="95.5" ></text>
</g>
<g >
<title>ipykernel/kernelbase.py(261):_dispatch_shell (623,012 us., 100.00%)</title><rect x="10.0" y="469" width="1180.0" height="15.0" fill="rgb(233,130,31)" rx="2" ry="2" />
<text  x="13.00" y="479.5" >ipykernel/kernelbase.py(261):_dispatch_shell</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (28,128 us., 4.51%)</title><rect x="259.7" y="133" width="53.2" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="262.66" y="143.5" >trans..</text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (108 us., 0.02%)</title><rect x="783.3" y="85" width="0.2" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="786.28" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,853 us., 0.30%)</title><rect x="648.8" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="651.78" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (274 us., 0.04%)</title><rect x="454.5" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="457.50" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (173 us., 0.03%)</title><rect x="1070.9" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1073.85" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_144 (3,437 us., 0.55%)</title><rect x="664.3" y="85" width="6.5" height="15.0" fill="rgb(243,175,41)" rx="2" ry="2" />
<text  x="667.29" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_81 (4,271 us., 0.69%)</title><rect x="176.9" y="85" width="8.1" height="15.0" fill="rgb(253,221,53)" rx="2" ry="2" />
<text  x="179.94" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_3 (14,878 us., 2.39%)</title><rect x="807.3" y="117" width="28.2" height="15.0" fill="rgb(246,189,45)" rx="2" ry="2" />
<text  x="810.29" y="127.5" >n..</text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (2,337 us., 0.38%)</title><rect x="587.3" y="69" width="4.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="590.31" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="455.9" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="458.93" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaAttention_20 (8,877 us., 1.42%)</title><rect x="647.3" y="117" width="16.8" height="15.0" fill="rgb(210,26,6)" rx="2" ry="2" />
<text  x="650.32" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,274 us., 0.20%)</title><rect x="547.5" y="69" width="2.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="550.54" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,270 us., 0.69%)</title><rect x="1042.6" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1045.62" y="79.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (3,216 us., 0.52%)</title><rect x="48.8" y="69" width="6.0" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="51.76" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (849 us., 0.14%)</title><rect x="641.5" y="85" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="644.47" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (268 us., 0.04%)</title><rect x="257.3" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="260.35" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (118 us., 0.02%)</title><rect x="48.5" y="85" width="0.3" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="51.53" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (206 us., 0.03%)</title><rect x="556.1" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="559.14" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_39 (816 us., 0.13%)</title><rect x="583.7" y="117" width="1.5" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="586.66" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (244 us., 0.04%)</title><rect x="515.2" y="53" width="0.5" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="518.21" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaDecoderLayer_6 (27,964 us., 4.49%)</title><rect x="965.6" y="149" width="53.0" height="15.0" fill="rgb(210,26,6)" rx="2" ry="2" />
<text  x="968.61" y="159.5" >nn.Mo..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,745 us., 2.37%)</title><rect x="987.1" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="990.10" y="111.5" >t..</text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,736 us., 0.28%)</title><rect x="792.4" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="795.39" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,728 us., 0.28%)</title><rect x="217.4" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="220.36" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_96 (4,306 us., 0.69%)</title><rect x="289.0" y="85" width="8.2" height="15.0" fill="rgb(214,43,10)" rx="2" ry="2" />
<text  x="292.02" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,256 us., 0.68%)</title><rect x="940.9" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="943.89" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,422 us., 0.39%)</title><rect x="157.7" y="53" width="4.6" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="160.66" y="63.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (1,765 us., 0.28%)</title><rect x="960.5" y="101" width="3.4" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="963.52" y="111.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_18 (11,817 us., 1.90%)</title><rect x="516.1" y="117" width="22.4" height="15.0" fill="rgb(247,194,46)" rx="2" ry="2" />
<text  x="519.10" y="127.5" >n..</text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (184 us., 0.03%)</title><rect x="156.6" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="159.60" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,987 us., 1.76%)</title><rect x="1126.1" y="101" width="20.8" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="1129.12" y="111.5" ></text>
</g>
<g >
<title>transformers/activations.py(149):_forward (92 us., 0.01%)</title><rect x="1014.9" y="69" width="0.1" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1017.86" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_1 (18,237 us., 2.93%)</title><rect x="606.1" y="117" width="34.6" height="15.0" fill="rgb(209,19,4)" rx="2" ry="2" />
<text  x="609.13" y="127.5" >nn..</text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (124 us., 0.02%)</title><rect x="543.8" y="85" width="0.2" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="546.79" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,277 us., 0.69%)</title><rect x="393.7" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="396.67" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (184 us., 0.03%)</title><rect x="1175.5" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="1178.46" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (188 us., 0.03%)</title><rect x="415.2" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="418.21" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (190 us., 0.03%)</title><rect x="906.5" y="85" width="0.3" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="909.48" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (597 us., 0.10%)</title><rect x="1145.2" y="69" width="1.1" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="1148.19" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,322 us., 0.37%)</title><rect x="734.2" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="737.24" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (60 us., 0.01%)</title><rect x="687.3" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="690.31" y="95.5" ></text>
</g>
<g >
<title>tornado/platform/asyncio.py(195):_start (623,012 us., 100.00%)</title><rect x="10.0" y="693" width="1180.0" height="15.0" fill="rgb(247,194,46)" rx="2" ry="2" />
<text  x="13.00" y="703.5" >tornado/platform/asyncio.py(195):_start</text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (62 us., 0.01%)</title><rect x="310.1" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="313.07" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (447 us., 0.07%)</title><rect x="384.1" y="69" width="0.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="387.08" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_13 (945 us., 0.15%)</title><rect x="1016.8" y="117" width="1.8" height="15.0" fill="rgb(210,23,5)" rx="2" ry="2" />
<text  x="1019.79" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_39 (4,266 us., 0.68%)</title><rect x="932.8" y="85" width="8.1" height="15.0" fill="rgb(233,132,31)" rx="2" ry="2" />
<text  x="935.81" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaMLP_10 (14,731 us., 2.36%)</title><rect x="124.9" y="117" width="27.9" height="15.0" fill="rgb(249,202,48)" rx="2" ry="2" />
<text  x="127.91" y="127.5" >n..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(194):_rotate_half (2,013 us., 0.32%)</title><rect x="870.4" y="69" width="3.8" height="15.0" fill="rgb(253,222,53)" rx="2" ry="2" />
<text  x="873.36" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,270 us., 0.20%)</title><rect x="174.0" y="85" width="2.4" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="176.97" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (2,314 us., 0.37%)</title><rect x="967.4" y="53" width="4.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="970.39" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (281 us., 0.05%)</title><rect x="1016.3" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="1019.25" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(2038):_silu (86 us., 0.01%)</title><rect x="1174.6" y="53" width="0.2" height="15.0" fill="rgb(213,40,9)" rx="2" ry="2" />
<text  x="1177.64" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,854 us., 0.30%)</title><rect x="691.1" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="694.13" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (266 us., 0.04%)</title><rect x="155.4" y="85" width="0.5" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="158.42" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (71 us., 0.01%)</title><rect x="362.2" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="365.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,729 us., 0.28%)</title><rect x="971.8" y="53" width="3.2" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="974.77" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_11 (924 us., 0.15%)</title><rect x="963.9" y="117" width="1.7" height="15.0" fill="rgb(222,82,19)" rx="2" ry="2" />
<text  x="966.86" y="127.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_8 (845 us., 0.14%)</title><rect x="902.6" y="117" width="1.6" height="15.0" fill="rgb(244,180,43)" rx="2" ry="2" />
<text  x="905.60" y="127.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,818 us., 0.29%)</title><rect x="1031.0" y="69" width="3.5" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="1034.03" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_56 (2,329 us., 0.37%)</title><rect x="1075.5" y="85" width="4.4" height="15.0" fill="rgb(240,162,38)" rx="2" ry="2" />
<text  x="1078.48" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_rsqrt_of_type_object_at_0x7b66dec9e9c0&gt; (65 us., 0.01%)</title><rect x="498.7" y="85" width="0.1" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="501.68" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(102):_forward (845 us., 0.14%)</title><rect x="902.6" y="101" width="1.6" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="905.60" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_masked_fill_of_Tensor_object_at_0x7b66858408b0&gt; (145 us., 0.02%)</title><rect x="1183.2" y="181" width="0.3" height="15.0" fill="rgb(217,57,13)" rx="2" ry="2" />
<text  x="1186.20" y="191.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (202 us., 0.03%)</title><rect x="868.3" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="871.30" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(638):_forward (22,473 us., 3.61%)</title><rect x="499.5" y="133" width="42.5" height="15.0" fill="rgb(243,178,42)" rx="2" ry="2" />
<text  x="502.47" y="143.5" >tran..</text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(331):_forward (10,710 us., 1.72%)</title><rect x="208.1" y="101" width="20.3" height="15.0" fill="rgb(208,15,3)" rx="2" ry="2" />
<text  x="211.13" y="111.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (70 us., 0.01%)</title><rect x="155.2" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="158.17" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (16,063 us., 2.58%)</title><rect x="70.7" y="101" width="30.4" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="73.67" y="111.5" >tr..</text>
</g>
<g >
<title>&lt;built-in_method_softmax_of_Tensor_object_at_0x7b6685840630&gt; (210 us., 0.03%)</title><rect x="803.7" y="69" width="0.4" height="15.0" fill="rgb(219,65,15)" rx="2" ry="2" />
<text  x="806.73" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (4,366 us., 0.70%)</title><rect x="280.7" y="53" width="8.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="283.75" y="63.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,273 us., 0.20%)</title><rect x="461.8" y="69" width="2.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="464.79" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (284 us., 0.05%)</title><rect x="963.3" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="966.32" y="95.5" ></text>
</g>
<g >
<title>torch/nn/functional.py(1811):_softmax (210 us., 0.03%)</title><rect x="927.7" y="85" width="0.4" height="15.0" fill="rgb(227,102,24)" rx="2" ry="2" />
<text  x="930.69" y="95.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(240):_forward (14,722 us., 2.36%)</title><rect x="932.6" y="101" width="27.9" height="15.0" fill="rgb(214,45,10)" rx="2" ry="2" />
<text  x="935.63" y="111.5" >t..</text>
</g>
<g >
<title>nn.Module:_Linear_139 (4,853 us., 0.78%)</title><rect x="572.8" y="85" width="9.2" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="575.82" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (6,032 us., 0.97%)</title><rect x="193.1" y="69" width="11.4" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="196.09" y="79.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_121 (1,264 us., 0.20%)</title><rect x="464.2" y="85" width="2.4" height="15.0" fill="rgb(225,93,22)" rx="2" ry="2" />
<text  x="467.20" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (4,277 us., 0.69%)</title><rect x="228.6" y="69" width="8.1" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="231.59" y="79.5" ></text>
</g>
<g >
<title>transformers/models/llama/modeling_llama.py(201):_apply_rotary_pos_emb (1,336 us., 0.21%)</title><rect x="661.2" y="85" width="2.5" height="15.0" fill="rgb(209,21,5)" rx="2" ry="2" />
<text  x="664.18" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_91 (2,330 us., 0.37%)</title><rect x="261.6" y="85" width="4.4" height="15.0" fill="rgb(246,191,45)" rx="2" ry="2" />
<text  x="264.56" y="95.5" ></text>
</g>
<g >
<title>torch/nn/modules/linear.py(113):_forward (1,713 us., 0.27%)</title><rect x="314.7" y="69" width="3.3" height="15.0" fill="rgb(232,127,30)" rx="2" ry="2" />
<text  x="317.74" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,728 us., 0.28%)</title><rect x="54.8" y="53" width="3.3" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="57.85" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_cat_of_type_object_at_0x7b66dec9e9c0&gt; (198 us., 0.03%)</title><rect x="457.2" y="85" width="0.4" height="15.0" fill="rgb(246,192,45)" rx="2" ry="2" />
<text  x="460.20" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_mean_of_Tensor_object_at_0x7b6685840950&gt; (168 us., 0.03%)</title><rect x="103.4" y="85" width="0.3" height="15.0" fill="rgb(217,56,13)" rx="2" ry="2" />
<text  x="106.36" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,757 us., 0.28%)</title><rect x="596.2" y="53" width="3.4" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="599.23" y="63.5" ></text>
</g>
<g >
<title>nn.Module:_LlamaRMSNorm_18 (939 us., 0.15%)</title><rect x="1174.8" y="117" width="1.8" height="15.0" fill="rgb(227,104,25)" rx="2" ry="2" />
<text  x="1177.80" y="127.5" ></text>
</g>
<g >
<title>&lt;built-in_method_pow_of_Tensor_object_at_0x7b6685840720&gt; (67 us., 0.01%)</title><rect x="1123.1" y="85" width="0.1" height="15.0" fill="rgb(234,134,32)" rx="2" ry="2" />
<text  x="1126.06" y="95.5" ></text>
</g>
<g >
<title>nn.Module:_Linear_95 (4,366 us., 0.70%)</title><rect x="280.7" y="85" width="8.3" height="15.0" fill="rgb(220,73,17)" rx="2" ry="2" />
<text  x="283.75" y="95.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (218 us., 0.03%)</title><rect x="559.2" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="562.20" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_method_reshape_of_Tensor_object_at_0x7b6685840090&gt; (224 us., 0.04%)</title><rect x="706.1" y="69" width="0.4" height="15.0" fill="rgb(237,148,35)" rx="2" ry="2" />
<text  x="709.11" y="79.5" ></text>
</g>
<g >
<title>&lt;built-in_function_linear&gt; (1,818 us., 0.29%)</title><rect x="1031.0" y="53" width="3.5" height="15.0" fill="rgb(232,125,29)" rx="2" ry="2" />
<text  x="1034.03" y="63.5" ></text>
</g>
<g >
<title>&lt;built-in_method_to_of_Tensor_object_at_0x7b66858401d0&gt; (281 us., 0.05%)</title><rect x="205.7" y="85" width="0.6" height="15.0" fill="rgb(242,173,41)" rx="2" ry="2" />
<text  x="208.72" y="95.5" ></text>
</g>
</g>
</svg>
